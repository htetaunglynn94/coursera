{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "prev_pub_hash": "e3bdf56ebd7061a73d2e31164d413959eab6f65df92ef251eaa6e5b63228d061"
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML240ENSkillsNetwork34171862-2022-01-01\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n    </a>\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Cross Validation\n\nEstimated time needed: **45** minutes\n\nWhen performing supervised machine learning analysis, it is common to withhold a portion of the data to test the final model's performance. This model testing is performed on the 'unseen' data, which the model was not trained on. This withholding of a portion of the dataset for testing is called Cross-Validation. Cross-Validation can also be used to select hyper-parameters and test the final model. In this section, we will focus on the test data only.\n\nCross-Validation also helps avoid over-fitting; a complex model could repeat the labels of the samples that it has just seen and, therefore, would have a perfect score but would fail to predict anything useful on the 'unseen' data. Furthermore, a complex model could just be modeling noise.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Cross validation method involves dividing the dataset into 3 parts:\n\n*   training set - is a portion of the data used for training the model\n*   validation set - is a portion of the data used to optimize the hyper-parameters of the model. This will     be illustrated in the next lab\n*   test set - is a portion of the data used to evaluate if the model generalizes enough to work on the     \n    data it was not trained on   \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "`Scikit Learn` library contains many methods that can perform the splitting of the data into training, testing and validation sets. The most popular methods that we will cover in this Jupyter Notebook are:\n\n*   train_test_split - creates a single split into train and test sets\n*   K-fold - creates number of k-fold splits, allowing cross validation\n*   cross_val_score - evaluates model's score through cross validation\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Objectives\n\nAfter completing this lab you will be able to:\n\n*   Understand how to split the data into a training and testing sets\n*   Understand and perform K-fold cross validation method\n*   Calculate Cross Validation Scores\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "***\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## **Setup**\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "For this lab, we will be using the following libraries:\n\n*   [`pandas`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML240ENSkillsNetwork34171862-2022-01-01) for managing the data.\n*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML240ENSkillsNetwork34171862-2022-01-01) for mathematical operations.\n*   [`seaborn`](https://seaborn.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML240ENSkillsNetwork34171862-2022-01-01) for visualizing the data.\n*   [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML240ENSkillsNetwork34171862-2022-01-01) for visualizing the data.\n*   [`sklearn`](https://scikit-learn.org/stable/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML240ENSkillsNetwork34171862-2022-01-01) for machine learning and machine-learning-pipeline related functions.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## **Import the required libraries**\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The following required modules are pre-installed in the Skills Network Labs environment. However, if you run this notebook commands in a different Jupyter environment (e.g. Watson Studio or Ananconda) you will need to install these libraries by removing the `#` sign before `!mamba` in the code cell below.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n#!mamba install -qy pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\n# Note: If your environment doesn't support \"!mamba install\", use \n# \"!pip install pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#!pip install -U scikit-learn",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Surpress warnings:\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import piplite\nawait piplite.install(['tqdm', 'seaborn', 'pandas', 'numpy', 'scikit-learn'])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np \n\nimport seaborn as sns \nimport matplotlib.pylab as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.preprocessing import StandardScaler, Normalizer\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import Pipeline",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## **Reading our data**\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "For this lab, we will be using the car sales dataset, hosted on IBM Cloud object storage. The dataset contains all the information about cars, the name of the manufacturer, the year it was launched, all car technical parameters, and the sale price. This dataset has already been pre-cleaned and encoded (using one-hot and label encoders) in the Linear Regression Notebook.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Let's read the data into *pandas* data frame and look at the first 5 rows using the `head()` method.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "We apply `dtypes.value_counts()` to see what types of data we have.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyodide.http import pyfetch\n \nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())\n \npath = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML240EN-SkillsNetwork/labs/encoded_car_data.csv\"\n \n#you will need to download the dataset; if you are running locally, please comment out the following \nawait download(path, \"encoded_car_data.csv\")\n \n \n# Import pandas library\nimport pandas as pd\n \n# Read the online file by the URL provides above, and assign it to variable \"df\"\ndata = pd.read_csv(\"encoded_car_data.csv\")\n \n# show the first 5 rows using dataframe.head() method\nprint(\"The first 5 rows of the dataframe\") \ndata.head(5)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "data.dtypes.value_counts()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can verify the data type using the method `info()`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "data.info()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "As we see from above, we now have only numeric parameters.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Data Preparation\n\nLet's first split our data into `X` features and `y` target.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X = data.drop(columns=['price'])\ny = data['price'].copy()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "# Train Test Split\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Now, we split our data into training and testing sets. Training data is used for our model to recognize patterns using some criteria, the test data is used for model evaluation, as shown in the image below.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<center>\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML240EN-SkillsNetwork/images/trin-test.png\">\n</center>\nsource scikit-learn.org\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "We use the function `train_test_split` that  splits arrays or matrices into random train and test subsets. The parameters of the `train_test_split` are:\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "`X,y`: the allowed inputs are lists, numpy arrays, scipy-sparse matrices or pandas data frames.\n\n`test_size`:  If float, it should be between 0.0 and 1.0 and represents the proportion of the dataset to include in the test split. If int (integer), it represents the absolute number of test samples. If None, the value is set to the complement of the train size. If train_size is also None, it will be set to 0.25.\n\nIn our example, we will use 30% of the data for testing and 70% for training.\n\n`random_state:` Controls the shuffling applied to the data before applying the split. Pass an int for reproducible output across multiple function calls. in our case, we set it to \"42\".\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Model Building and Evaluation\n\nLet's perform linear regression using traditional `train_test_split`, which will split the data into train and test set, so that each target value appears in both training and testing sets. We will start by creating a `LinearRegression()` object, lr.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "lr = LinearRegression()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We apply the `LinearRegression()` model, m, and `fit()` our `X_train` and `  y_train `  training data.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "lr.fit(X_train, y_train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "To make our predictions, we need to use our test data set. We apply `predict()` function on the testing data set.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "predicted = lr.predict(X_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "predicted[:5]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Now, let's check some evaluation statistics, such as the coefficient of determination, $R^{2}$, using the built-in method `score` or  `r2_score`, and the Root Mean Square Error, RMSE, for which we can use the `mean_squared_error` method, MSE.\n\nThe $R^{2}$ statistic indicates the percentage of the variance in the dependent variable that the independent variables explain collectively.\n\nRoot Mean Square Error (RMSE) is the standard deviation of the residuals (prediction errors). Residuals are a measure of how far from the regression line data points are; RMSE is a measure of how spread out these residuals are. In other words, it tells you how concentrated the data is around the line of best fit.\n\nFor more information on [R-squared](https://en.wikipedia.org/wiki/Coefficient_of_determination?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML240ENSkillsNetwork34171862-2022-01-01) and [RMSE](https://en.wikipedia.org/wiki/Root-mean-square_deviation?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML240ENSkillsNetwork34171862-2022-01-01), please visit their corresponding documentations.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "lr.score(X_train, y_train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "r2_score(y_test, predicted)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Using the training data only, the $R^{2}$ is \\~ 0.93. So, almost 93% of variability in the training data is explained by our model.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Using the test data  $R^{2}$, we get \\~0.85, not as good as the previous score.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "lr.score(X_test, y_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can also use  `r2_score()` method to calculate the $R^2$. It will provide the same result.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(r2_score(y_true=y_test, y_pred=predicted))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Now, let's calculate the RMSE. The smaller the RMSE number the better our model is.\nWe apply `mean_squared_error` to our `y_test`and our predicted data. Then, we take a square root of our MSE, using `np.sqrt()` function.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "mse = mean_squared_error(y_true=y_test, y_pred=predicted)\nrmse = np.sqrt(mse)\nrmse",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Prediction Example\n\nLet's select some random data, using `iloc` and see some predicted versus actual values for the car prices.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "some_data = X.iloc[:3]\nsome_labels = y.iloc[:3]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "print(\"Predictions:\", lr.predict(some_data))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "print(\"Labels:\", list(some_labels))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "predicted = lr.predict(X_test)\npredicted",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can also use the pipeline to run operations on our data. For example we can standardize our data then perform linear regression by applying the method <code>fit</code>.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pipe = Pipeline([('ss',StandardScaler() ), ('lr', LinearRegression())])\npipe.fit(X_train,y_train)\npipe",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Let's calculate the R squared.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pipe.score(X_train, y_train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Using the training data only, the R squared is \\~ 0.93.\\\nNow, let's check the R squared on the test set.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pipe.score(X_test, y_test)\n# Negative R-squared value means the model is too complex and overfitting.",
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "The R squared is much lower. This value provides more accurate evaluation of our model since we test our model on the 'unseen' data set. In case if the R squared is negative, it is because the model is too complex and the data is overfitting. For more information, please, visit this [documentation](https://en.wikipedia.org/wiki/Overfitting?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML240ENSkillsNetwork34171862-2022-01-01) on overfitting.\n\nThis will make more sense when we explore polynomial regression.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Exercise 1\n\nCreate a pipeline object called pipe1, replace standardization with normalization. Calculate the $R^{2}$ using the built-in method `score` and for RMSE, using `mean_squared_error` method.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Enter your code and run the cell\npipe1 = Pipeline([('normalize', Normalizer()), ('lr', LinearRegression())])\npipe1.fit(X_train, y_train)\n\nprint(\"R2 values for train_data:\", pipe1.score(X_train, y_train))\nprint(\"R2 values for test_data:\", pipe1.score(X_test, y_test))\n\npred = pipe1.predict(X_test)\n\nmse  = mean_squared_error(y_true=y_test, y_pred=pred)  # mean-square error\nrmse = np.sqrt(mse)                                    # root-mean-square error\nrmse",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<details>\n<summary><strong>Solution</strong> (Click Here)</summary>\n    &emsp; &emsp; <code>\n\npipe\\_1 = Pipeline(\\[('nn',Normalizer() ),('lr', LinearRegression())])\npipe\\_1.fit(X_train, y_train)\n\npipe\\_1.score(X_train,y_train)\npipe\\_1.score(X_test,y_test)\n\npred =pipe\\_1.predict(X_test)\n\nmse = mean_squared_error(y_true=y_test, y_pred=pred)\nrmse = np.sqrt(mse)\nrmse\n\n</code>\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## One feature\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "We can use the test data to select a feature with the best performance. We have a list of features:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "features = list(X)\nfeatures",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can train a linear regression model using each feature and use the test data to obtain the best feature.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "R_2  = []\npipe = Pipeline([('ss', StandardScaler() ),('lr', LinearRegression())])\n\nfor feature in features:\n    pipe.fit(X_train[[feature]],y_train)\n    R_2.append(pipe.score(X_train[[feature]],y_train))\n\nlist(zip(features, R_2))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can plot the $R^{2}$ for each feature.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "plt.bar(features, R_2)\nplt.xticks(rotation=90)\nplt.ylabel(\"$R^2$\")\nplt.show()",
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Now, we select the feature that works best, using `argmax()` function.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "best = features[np.argmax(R_2)]\nbest",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "So, 'enginesize' is the feature that produces the highest $R^{2}$. We then train the feature that works best using all the data.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pipe.fit(X[[best]], y)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Exercise 2\n\nIn this Exercise, find the best feature using the test data, without standardization.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Enter your code and run the cell\nlr = LinearRegression()\nR2 = []\n\nfor feature in features:\n    lr.fit(X_train[[feature]], y_train)\n    R2.append(lr.score(X_train[[feature]], y_train))\n\n# visualization\nplt.bar(features, R2)\nplt.xticks(rotation=90)\nplt.ylabel('$R^2$')\nplt.show()\n\n# find the highest score\nfeatures[np.argmax(R2)]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<details>\n<summary><strong>Solution</strong> (Click Here)</summary>\n<code>\nR_2=[]\n\nfor feature in features:\n      lr.fit(X_train[[feature]], y_train)\n      R_2.append(lr.score(X_test[[feature]],y_test))\nbest=features[np.argmax(R_2)]\nplt.bar(features,R_2)\nplt.xticks(rotation=90)\nplt.ylabel(\"$R^2$\")\nplt.show()\nbest=features[np.argmax(R_2)]\nprint(best)\n\n</code>\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# K Fold Cross Validation\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample.\n\nThe procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. As such, the procedure is often called k-fold cross-validation. When a specific value for k is chosen, it may be used in place of k in the reference to the model, such as k=5 becoming 5-fold cross-validation, as shown in the Diagram below. In this case, we would use K-1 (or 4 folds) for testing a 1 fold for training. K-fold is also used for hyper-parameters selection that we will discuss later.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<center>\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML240EN-SkillsNetwork/images/k-fold.png\">\n</center>\n<center>source scikit-learn.org</center>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Cross Validation Score\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Now, let's use *Scikit-Learn's* *K-fold cross-validation* method to see whether we can assess the performance of our model. The *K-fold cross-validation* method splits the training set into the number of folds (n_splits), as now in the Diagram above, if we have K folds, K-1 is used for training and one fold is used for testing. The input parameters are as follows:\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<b>estimatorestimator</b>: The object to use to `fit` the data.\n\n<b>X</b>: array-like of shape (n_samples, n_features). The data to fit. Can be for example a list, or an array.\n\n<b>y</b>: array-like of shape (n_samples,) or (n_samples, n_outputs), default=None. The target variable to try to predict in the case of supervised learning.\n\n<b>scoring</b>: A str or a scorer callable object/ function with signature scorer (estimator, X, y) which should return only a single value.  See model evaluation [documentation](https://scikit-learn.org/stable/modules/model_evaluation.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML240ENSkillsNetwork34171862-2022-01-01#scoring-parameter) for more information.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "N = len(X)\nN",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "X.shape",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Now, let's create a Linear Regression object.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "lr = LinearRegression()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Then, calculate cross validation scores based on our testing sets.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "scores = cross_val_score(estimator=lr, \n                         X=X, \n                         y=y, \n                         scoring=\"r2\", \n                         cv=3)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Now, we have the $R^{2}$ for each fold not used to train the model.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "scores ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can calculate mean and standard deviation using the following function of the `scores`:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def display_scores(scores, print_=False):\n    \n    print(\"Scores:\", scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard deviation:\", scores.std())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "display_scores(scores)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "The larger the fold, the better the model performance is, as we are using more samples for training; the variance also decreases.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Cross Validation Scores are RMSE values for training the data on each of our folds, in our case cv = 3, so we get 3 scores, 1 for each fold.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Exercise 3\n\nIn this Exercise, compute the cross validation scores for 5 folds, using the linear regression object `lr` and `neg_mean_squared_error` method for scoring.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Enter your code and run the cell\nscores = cross_val_score(estimator=lr, \n                          X=X, \n                          y=y,\n                          scoring=\"neg_mean_squared_error\",\n                          cv=5)\nlr_scores = np.sqrt(-scores)\n\ndisplay_scores(lr_scores)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<details>\n<summary><strong>Solution</strong> (Click Here)</summary>\n    &emsp; &emsp; <code>\n\nscores = cross_val_score(lr, X ,y, scoring =\"neg_mean_squared_error\", cv=5)\nlr_scores = np.sqrt(-scores)\ndisplay_scores(lr_scores)\n\n</code>\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### K Fold\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In many cases, we would like to train models that are not available in Scikit-learn or are too large to fit in the memory. We can create a `KFold` object that  Provides train/test indices to split data into train/test sets in an iterative manner.\n\n`n_splitsint`:  A number of folds. Must be at least 2. Changed in version 0.22: n_splits default value changed from 3 to 5.\n\n`shuffle`: Indicates whether to shuffle the data before splitting into batches. Note, the samples within each split will not be shuffled.\n\n`random_state`: the random state.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "We create the  `KFold` object `kf`, setting the number of splits to 2.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "n_splits = 2\nkf = KFold(n_splits=n_splits)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 52
    },
    {
      "cell_type": "markdown",
      "source": "We train the model using the `split(X,y)` method. It provides the train/test indices for `X` and `y`. Half the data is used for training in the first iteration, and the rest is used for testing and displaying the indexes for each set.  For the second iteration, the data used for training is used for testing, and the testing data is used for training. We store the $R^2$ for each iteration in the array  `R_2`. The `np.zeros()` function returns a new array of given shape and type, filled with zeros. Then, we calculate the $R^2$ for each of the X_train and X_test splits.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "y   = data['price'].copy()\nX   = data.drop(columns=['price'])\nR_2 = np.zeros((n_splits, 1))    # 2 rows & 1 column\nR_2",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 57,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[0.],\n       [0.]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 57
    },
    {
      "cell_type": "code",
      "source": "pipe = Pipeline([('ss', StandardScaler()), ('lr', LinearRegression())])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 61
    },
    {
      "cell_type": "code",
      "source": "kf.split(X, y)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 60,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<generator object _BaseKFold.split at 0xd89fb48>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 60
    },
    {
      "cell_type": "code",
      "source": "n = 0\nfor k, (train_index, test_index) in enumerate(kf.split(X, y)):\n    \n    print(\"n =\", n)\n    print(\"TRAIN:\", train_index)\n    print(\"TEST :\", test_index )\n\n    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y[train_index], y[test_index]\n    pipe.fit(X_train, y_train)\n    n =+ 1\n    \n    R_2[k] = pipe.score(X_test, y_test)    \n    print(R_2)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "n = 0\nTRAIN: [103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120\n 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138\n 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156\n 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174\n 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192\n 193 194 195 196 197 198 199 200 201 202 203 204]\nTEST : [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102]\n[[-6.37762570e+26]\n [-2.46096538e+25]]\nn = 1\nTRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102]\nTEST : [103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120\n 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138\n 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156\n 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174\n 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192\n 193 194 195 196 197 198 199 200 201 202 203 204]\n[[-6.37762570e+26]\n [-2.46096538e+25]]\n"
        }
      ],
      "execution_count": 67
    },
    {
      "cell_type": "markdown",
      "source": "We can calculate the average $R^2$.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "R_2.mean()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 68,
          "output_type": "execute_result",
          "data": {
            "text/plain": "np.float64(-3.3118611189512e+26)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 68
    },
    {
      "cell_type": "markdown",
      "source": "If we set the number of splits to three, we see 2/3's of the data is used for training.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "n_splits = 3\nkf   = KFold(n_splits=n_splits)\ny    = data['price'].copy()\nX    = data.drop(columns=['price'])\nR_2  = np.zeros((n_splits, 1))\npipe = Pipeline([('ss', StandardScaler()), ('lr', LinearRegression())])\n\nn    = 0\n\nfor k, (train_index, test_index) in enumerate(kf.split(X, y)):\n    print('n =', n)\n    print('TRAIN:', train_index)\n    print('TEST:', test_index)\n\n    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y[train_index], y[test_index]\n    pipe.fit(X_train, y_train)\n    n =+ 1\n    R_2[k] = pipe.score(X_test, y_test)\n\nR_2.mean()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "n = 0\nTRAIN: [ 69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86\n  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104\n 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122\n 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158\n 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176\n 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194\n 195 196 197 198 199 200 201 202 203 204]\nTEST: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68]\nn = 1\nTRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68 137 138 139\n 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157\n 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175\n 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193\n 194 195 196 197 198 199 200 201 202 203 204]\nTEST: [ 69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86\n  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104\n 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122\n 123 124 125 126 127 128 129 130 131 132 133 134 135 136]\nn = 1\nTRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136]\nTEST: [137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154\n 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172\n 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190\n 191 192 193 194 195 196 197 198 199 200 201 202 203 204]\n"
        },
        {
          "execution_count": 70,
          "output_type": "execute_result",
          "data": {
            "text/plain": "np.float64(-1.1543623963173812e+27)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 70
    },
    {
      "cell_type": "markdown",
      "source": "## Exercise 4\n\nIt many applications, it is useful to randomly select samples for K fold cross validation. In this Exercise, randomly select samples by setting `shuffle` to `True` in the `KFold` constructor. Use all the parameters, as above.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "n_splits = 3\nkf   = KFold(n_splits=n_splits, shuffle=True)\ny    = data['price'].copy()\nX    = data.drop(columns=['price'])\nR_2  = np.zeros((n_splits, 1))\npipe = Pipeline([('ss', StandardScaler()), ('lr', LinearRegression())])\n\nn    = 0\n\nfor k, (train_index, test_index) in enumerate(kf.split(X, y)):\n    print('n =', n)\n    print('TRAIN:', train_index)\n    print('TEST:', test_index)\n\n    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y[train_index], y[test_index]\n    pipe.fit(X_train, y_train)\n    n =+ 1\n    R_2[k] = pipe.score(X_test, y_test)\n\nR_2.mean()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "n = 0\nTRAIN: [  0   1   2   4   5   8   9  10  11  12  13  15  19  20  22  23  24  25\n  26  27  28  29  32  33  34  35  36  37  40  44  45  46  48  50  52  54\n  55  56  57  58  60  61  67  68  70  71  72  74  75  76  77  78  80  83\n  84  85  86  87  91  93  94  95  97  98  99 100 101 103 104 105 106 108\n 109 110 111 112 114 116 118 120 121 122 123 126 127 128 129 130 131 133\n 135 137 139 141 142 143 144 145 146 147 148 149 151 153 154 155 156 157\n 159 160 161 162 163 165 167 168 169 170 171 173 174 175 177 180 182 183\n 186 187 188 193 194 196 197 199 200 202]\nTEST: [  3   6   7  14  16  17  18  21  30  31  38  39  41  42  43  47  49  51\n  53  59  62  63  64  65  66  69  73  79  81  82  88  89  90  92  96 102\n 107 113 115 117 119 124 125 132 134 136 138 140 150 152 158 164 166 172\n 176 178 179 181 184 185 189 190 191 192 195 198 201 203 204]\nn = 1\nTRAIN: [  0   2   3   5   6   7  10  13  14  15  16  17  18  19  21  22  23  24\n  27  29  30  31  32  33  34  38  39  41  42  43  47  48  49  51  52  53\n  54  55  57  58  59  61  62  63  64  65  66  67  69  72  73  74  76  79\n  81  82  83  84  85  86  88  89  90  91  92  94  96  97  98 101 102 103\n 106 107 108 110 112 113 114 115 117 119 120 121 122 123 124 125 126 128\n 129 130 132 134 136 137 138 139 140 141 146 147 148 150 151 152 155 158\n 159 160 162 164 166 169 171 172 176 177 178 179 180 181 182 184 185 189\n 190 191 192 193 195 196 197 198 201 203 204]\nTEST: [  1   4   8   9  11  12  20  25  26  28  35  36  37  40  44  45  46  50\n  56  60  68  70  71  75  77  78  80  87  93  95  99 100 104 105 109 111\n 116 118 127 131 133 135 142 143 144 145 149 153 154 156 157 161 163 165\n 167 168 170 173 174 175 183 186 187 188 194 199 200 202]\nn = 1\nTRAIN: [  1   3   4   6   7   8   9  11  12  14  16  17  18  20  21  25  26  28\n  30  31  35  36  37  38  39  40  41  42  43  44  45  46  47  49  50  51\n  53  56  59  60  62  63  64  65  66  68  69  70  71  73  75  77  78  79\n  80  81  82  87  88  89  90  92  93  95  96  99 100 102 104 105 107 109\n 111 113 115 116 117 118 119 124 125 127 131 132 133 134 135 136 138 140\n 142 143 144 145 149 150 152 153 154 156 157 158 161 163 164 165 166 167\n 168 170 172 173 174 175 176 178 179 181 183 184 185 186 187 188 189 190\n 191 192 194 195 198 199 200 201 202 203 204]\nTEST: [  0   2   5  10  13  15  19  22  23  24  27  29  32  33  34  48  52  54\n  55  57  58  61  67  72  74  76  83  84  85  86  91  94  97  98 101 103\n 106 108 110 112 114 120 121 122 123 126 128 129 130 137 139 141 146 147\n 148 151 155 159 160 162 169 171 177 180 182 193 196 197]\n"
        },
        {
          "execution_count": 71,
          "output_type": "execute_result",
          "data": {
            "text/plain": "np.float64(-1.3715417894925515e+24)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 71
    },
    {
      "cell_type": "markdown",
      "source": "<details>\n<summary><strong>Solution</strong> (Click Here)</summary>\n    &emsp; &emsp; <code>\n\nn_splits=3\nkf = KFold(n_splits = n_splits,shuffle=True)\ny = data['price'].copy()\nX = data.drop(columns=['price'])\nR_2=np.zeros((n_splits,1))\npipe = Pipeline([('ss',StandardScaler() ),('lr', LinearRegression())])\nn=0\nfor k,(train_index, test_index) in enumerate(kf.split(X,y)):\n    print(\"TRAIN:\", train_index)\n    print(\"TEST:\", test_index)\n    X_train, X_test =X.iloc[train_index],X.iloc[test_index]\n    \n    y_train, y_test=y[train_index],y[test_index]\n    pipe.fit(X_train,y_train)\n    n=+1\n    R_2[k]=pipe.score(X_test, y_test)\n    \n    \nR_2.mean()\n\n</code>\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In the Regularization lab, we will learn how to use cross validation to select hyper-parameters.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Congratulations! - You have completed the lab\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Authors\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2021-01-01\" target=\"_blank\">Joseph Santarcangelo</a>\n\n[Svitlana Kramar](https://www.linkedin.com/in/svitlana-kramar?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML240ENSkillsNetwork34171862-2022-01-01)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<!--## Change Log\n-->\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<!--| Date (YYYY-MM-DD) | Version | Changed By  | Change Description             |\n| ----------------- | ------- | ----------- | ------------------------------ |\n| 2022-03-25        | 0.1     | Joseph S.   | Updated all content            |\n| 2022-04-26        | 0.1     | Svitlana K. | Corrected minor grammar errors |-->\n",
      "metadata": {}
    }
  ]
}