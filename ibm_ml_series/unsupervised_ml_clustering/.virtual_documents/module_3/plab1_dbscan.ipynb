









































# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.
#!mamba install -qy pandas==1.3.4 numpy==1.21.4 matplotlib==3.5.0 scikit-learn==0.20.1 scipy==1.7.3
# Note: If your environment doesn't support "!mamba install", use "!pip install pandas==1.3.4 ..."





def warn(*args, **kwargs):
    pass

import warnings
warnings.warn = warn


import string
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline
sns.set_context('notebook')
sns.set_style('white')

from sklearn.cluster import DBSCAN         # clustering model
from sklearn.datasets import load_digits   # datasets

# t-distributed Stochastic Neighbor Embedding (dimensionality reduction)
from sklearn.manifold import TSNE


# Surpress any warnings:
def warn(*args, **kwargs):
    pass
import warnings
warnings.warn = warn
import string

import pandas as pd
import numpy as np
from sklearn.cluster import DBSCAN
from sklearn.manifold import TSNE
from sklearn.datasets import load_digits

import seaborn as sns

sns.set_context('notebook')
sns.set_style('white')

# Import matplotlib for 3d plotting:
import matplotlib.pyplot as plt

# Make matplotlib work in jupyter notebook
%matplotlib inline











url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/data/example1.csv'


df = pd.read_csv(url)
df





# 312 runtime configuration parameters -->['figure.figsize']
plt.rcParams['figure.figsize']


plt.rcParamsDefault['figure.figsize']


plt.rcParams['figure.figsize'] = plt.rcParamsDefault['figure.figsize']


string.ascii_uppercase


for p in df.iterrows():
    print(p)     # (index no, column   value)
    print(p[1])  # without index no
    print(p[1][0] + 0.2, "|", p[1][1])


plt.figure(figsize=(2,2))
plt.annotate(text='A', xy = (-3, 0))
plt.xlim(-4,4)
plt.ylim(-1, 4)
plt.show()


plt.scatter(df['0'], df['1'])
for t, p in zip(string.ascii_uppercase, df.iterrows()):
    plt.annotate(text=t, xy = (p[1][0] + 0.2, p[1][1]))
plt.show()





cluster = DBSCAN(eps=3, min_samples=4)
cluster.fit(df)


cluster.labels_


np.unique(cluster.labels_, return_counts=True) # -1 means outlier


cls = len(set(cluster.labels_) - set([-1]))
cls


outlier = (cluster.labels_ == -1).sum()
outlier


print(f"DBSCAN found {cls} clusters and {outlier} points of noise.")





['blue','red'][-1]


plt.rcParams['figure.figsize'] = plt.rcParamsDefault['figure.figsize']
plt.scatter(df['0'], df['1'], c=[['blue','red'][cl] for cl in cluster.labels_])
plt.scatter(0,0, c='blue', alpha=0.2, s=80000)
plt.scatter(6,0, c='red', alpha=0.2, s=900)
for t, p in zip(string.ascii_uppercase, df.iterrows()):
    plt.annotate(t, (p[1][0] + 0.2, p[1][1]))
plt.show()











url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/data/012.csv'


df = pd.read_csv(url)
df.head()





friend_digits = df.iloc[:, df.columns != 'y'].to_numpy()
friend_digits


plt.rcParams['figure.figsize'] = (8,6)
# only tuple "( )" can be used for iterator object
it = (x.reshape(8,8) for x in friend_digits)  # iterated object will be generated
# only tuple "( )" can be used for iterator object
c = 3
fig, ax = plt.subplots(1, c, sharex='col', sharey='row') # common X and Y axes
for j in range(c):
    ax[j].axis('off')
    ax[j].set_title(f"Friend\'s number: {j}")
    ax[j].imshow(next(it))  # show image of iterated objects
plt.show()


it = (x.reshape(8,8) for x in friend_digits)
next(it)


plt.rcParams['figure.figsize'] = plt.rcParamsDefault['figure.figsize']





# Load the data
digits, y = load_digits(return_X_y=True) # separate data into 'X' and 'y'


digits


y


pd.DataFrame(digits).head()





plt.rcParams['figure.figsize'] = (8,6)
it = (x.reshape(8,8) for x in digits)
r, c = 3, 5
fig, ax = plt.subplots(r, c, sharex='col', sharey='row')
for i in range(r):
    for j in range(c):
        ax[i, j].axis('off')
        ax[i, j].imshow(next(it))
plt.show()
plt.rcParams['figure.figsize'] = plt.rcParamsDefault['figure.figsize']





# np.r_[A , B] is used for concatenation of arrays
np.r_[np.array([[0,0],[1,1]]), np.array([[2,2]])]


data = np.r_[digits, friend_digits]
y = np.r_[y, df['y']]


data.shape, digits.shape, friend_digits.shape


y.shape





embedding = TSNE(n_components = 2,   # reduce High-D data to 2-D 
                 init = 'pca',    # Principal Components Analysis
                 n_iter = 500, # number of iterations
                 n_iter_without_progress = 150, # stop optimization if no improvement until 150 times
                 perplexity = 10,  # control balance between local and global structure
                 random_state = 0)


data.shape


e_data = embedding.fit_transform(data)
e_data.shape





n = friend_digits.shape[0]
n


e_data[:-3]


plt.rcParams['figure.figsize'] = (20,15)

plt.scatter(e_data[:-n, 0],       # 1st col
            e_data[:-n, 1],       # 2nd col
            marker = 'o',         # symbol type
            alpha = 0.75,         # transpancy
            label = 'mnist data', # data label for legend
            s = 100)              # size of symbol

plt.scatter(e_data[-n:, 0], 
            e_data[-n:, 1], 
            marker = 'x', 
            color = 'red', 
            label = 'friend\'s data', 
            alpha = 1, 
            s = 100)

plt.legend(bbox_to_anchor=[1, 1])
plt.show()
plt.rcParams['figure.figsize'] = plt.rcParamsDefault['figure.figsize']





cluster = DBSCAN(eps=5, min_samples=20)
cluster.fit(e_data)
print(f'DBSCAN found {len(set(cluster.labels_) - set([-1]))} clusters and {(cluster.labels_ == -1).sum()} points of noise.')





np.unique(cluster.labels_, return_counts=True) # 25 outliers


plt.cm.get_cmap('brg', 2)


e_data[:, 0]


-1 % 2


len(set(cluster.labels_))


plt.rcParams['figure.figsize'] = (20, 15)  # set figure size
unique_labels = set(cluster.labels_)    # {-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11}
n_labels = len(unique_labels)           # 13 labels
cmap = plt.cm.get_cmap('brg', n_labels) # cmap range

for l in unique_labels:   # -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11
    plt.scatter(e_data[cluster.labels_ == l, 0],      # conditional 1st col
                e_data[cluster.labels_ == l, 1],      # conditional 2nd col
                c = [cmap(l) if l >= 0 else 'red'],   # each color for normal pts | red for outliers 
                marker ='ov'[l % 2],   # l % 2 = 0 or 1 (remainder)
                alpha = 0.75,          # transparency
                s = 100,               # size of data plot
                label = f"Cluster {l}" if l >= 0 else 'Noise') # -1 = 'Noise', 0 = 'Cluster 0'

plt.legend(bbox_to_anchor = [1,1])
plt.show()
plt.rcParams['figure.figsize'] = plt.rcParamsDefault['figure.figsize']


print("The predicted labels of our friend's handwriting:")
print(cluster.labels_[-3:])





np.random.choice(10, 3, replace=False) # 10 looks like range(10) --> 0 to 9


r, c = 1, 5     # set configuration
plt.rcParams['figure.figsize'] = (4*r, 4*c)
for label in unique_labels:
    cluster_data = data[cluster.labels_ == label]
    nums = cluster_data[np.random.choice(len(cluster_data), r * c, replace=False)]
    it =(x.reshape(8,8) for x in nums)
    fig, ax = plt.subplots(r, c)
    ax = ax.reshape(r, c)
    plt.subplots_adjust(wspace=0.1, hspace=-0.69)
    
    fig.suptitle(f'Original data from cluster {label}', fontsize=20, y=0.545)

    for i in range(r):
        for j in range(c):
            ax[i, j].axis('off')
            ax[i, j].imshow(next(it))

plt.show()
plt.rcParams['figure.figsize'] = plt.rcParamsDefault['figure.figsize']





print('Correct labels:')
plt.rcParams['figure.figsize'] = (20,15)

unique_labels = set(y)
n_labels = len(unique_labels)
cmap = plt.cm.get_cmap('brg', n_labels)
for l in unique_labels:
    plt.scatter(
        e_data[y == l, 0],
        e_data[y == l, 1],
        c=[cmap(l)],
        marker=f'${l}$',
        alpha=1,
        label=f'{l}',
        s=100)
plt.legend(bbox_to_anchor=[1, 1])
plt.show()





for i, (l, t) in enumerate(zip(cluster.labels_[-3:], y[-3:])):
    print('-' * 30)
    print(f'Your friend\'s {i}th sample was categorized as being in cluster #{l}')
    if l == -1:
        print('(IE: Noise)')
    else:
        v, c = np.unique(y[cluster.labels_ == l], return_counts=True)
        mfreq = v[np.argmax(c)]
        ratio = c.max() / c.sum()
        print(f'Cluster {l} is {ratio * 100:.2f}% the number {mfreq}')
        
    print(f'Your friend\'s {i}th sample is supposed to be the number {t}')








df = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/data/DBSCAN_exercises.csv')
df.head()





plt.scatter(df['x'], df['y'])
plt.show()





# TODO









# TODO









# TODO

























