












































 # All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.
#!mamba install -qy pandas==1.3.4 numpy==1.21.4 matplotlib==3.5.0 scipy==1.7.3
!mamba install -qy scikit-learn==1.0.2
# Note: If your environment doesn't support "!mamba install", use "!pip install pandas==1.3.4 ... "





import sklearn
if sklearn.__version__ != "1.0.2":
    raise ValueError("Please install sklearn==1.0.2 so this lab works properly")





def warn(*args, **kwargs):
    pass

import warnings
warnings.warn = warn


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# Make matplotlib work in jupyter notebook
%matplotlib inline

# import scipy
from scipy.spatial.distance import euclidean, cityblock, cosine
# import sklearn.metrics.pairwise





# This function will allow us to find the average distance between two sets of data
def avg_distance(X1, X2, distance_func):
    from sklearn.metrics import jaccard_score
    #print(distance_func)
    res = 0
    for x1 in X1:
        for x2 in X2:
            if distance_func == jaccard_score: # the jaccard_score function only returns jaccard_similarity
                res += 1 - distance_func(x1, x2)
            else:
                res += distance_func(x1, x2)
    return res / (len(X1) * len(X2))





# This function will allow us to find the average pairwise distance
def avg_pairwise_distance(X1, X2, distance_func):
    return sum(map(distance_func, X1, X2)) / min(len(X1), len(X2))





df = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/iris.csv')
df.head()





df.drop(['petal_width'], axis=1, inplace=True)
df.head()





species = df['species'].unique()
print(species)





attrs = ['sepal_length','sepal_width','petal_length']
markers = ['o','v','^']
fig = plt.figure()
ax = fig.add_subplot(projection='3d')
for specie, marker in zip(species, markers):
    # Store 3 features' data separately without 'species'
    specie_data = df[df['species'] == specie][attrs]
    # Separate data into features by features
    xs, ys, zs = [specie_data[attr] for attr in attrs]
    # Plot 3 dimensions with different symbols
    ax.scatter(xs, ys, zs, marker=marker)
plt.show()





seto, vers, virg = [df.loc[df.species == specie][attrs].to_numpy() for specie in species]








seto.shape, vers.shape, virg.shape











euclidean([0, 0], [3, 4])


# Test
from math import sqrt
sqrt((3-0)**2 + (4-0)**2)











def avg_distance(X1, X2, distance_func):
    from sklearn.metrics import jaccard_score
    res = 0
    for x1 in X1:
        for x2 in X2:
            if distance_func == jaccard_score


# This function will allow us to find the average distance between two sets of data
def avg_distance(X1, X2, distance_func):
    from sklearn.metrics import jaccard_score
    #print(distance_func)
    res = 0
    for x1 in X1:
        for x2 in X2:
            if distance_func == jaccard_score: # the jaccard_score function only returns jaccard_similarity
                res += 1 - distance_func(x1, x2)
            else:
                res += distance_func(x1, x2)
    return res / (len(X1) * len(X2))


avg_distance(setosa_data, versicolor_data, euclidean)





avg_distance(setosa_data, virginica_data, euclidean)





from sklearn.metrics.pairwise import paired_euclidean_distances





X = np.array([[0, 0]], dtype=float)
Y = np.array([[3, 4]], dtype=float)
paired_euclidean_distances(X, Y).mean()





avg_pairwise_distance(X, Y, euclidean)





M, N = setosa_data.shape
print(f'{M} points and each column is {N} dimensions')





row_dist=paired_euclidean_distances(setosa_data, versicolor_data)
row_dist





row_dist.mean()





paired_euclidean_distances(setosa_data, virginica_data).mean()





avg_pairwise_distance(setosa_data, virginica_data, euclidean)











cityblock([1, 1], [-2, 2])





avg_distance(setosa_data, setosa_data, cityblock)





avg_distance(setosa_data, versicolor_data, cityblock)





avg_distance(setosa_data, virginica_data, cityblock)





from sklearn.metrics.pairwise import manhattan_distances


X = np.array([[1, 1]])

Y = np.array([[-2, 2]])


manhattan_distances(X, Y)











cosine([1, 1], [-1, -1])





df = pd.read_csv(
    'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/auto-mpg.data',
    header=None, delim_whitespace=True,
    names=['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'car_name'])
df.head()





df['car_name'] = df['car_name'].str.split(n=1).apply(lambda lst: lst[0]).replace('chevrolet', 'chevy')
df.rename(columns={'car_name': 'make'}, inplace=True)
df = df[['mpg', 'weight', 'make']]
df.head()





dfn = df[['mpg', 'weight']]
df[['mpg', 'weight']] = (dfn-dfn.min())/(dfn.max()-dfn.min())
df.head()





chevy = df.loc[df['make'] == 'chevy']
honda = df.loc[df['make'] == 'honda']

plt.scatter(chevy['mpg'], chevy['weight'], marker='o', label='chevy')
plt.scatter(honda['mpg'], honda['weight'], marker='^', label='honda')
plt.xlabel('mpg')
plt.ylabel('weight')
plt.legend()
plt.show()





chevy_data = chevy[['mpg', 'weight']].to_numpy()
honda_data = honda[['mpg', 'weight']].to_numpy()





avg_distance(chevy_data, chevy_data, cosine)





avg_distance(honda_data, honda_data, cosine)





avg_distance(honda_data, chevy_data, cosine)





from sklearn.metrics.pairwise import cosine_distances


X = np.array([[1, 1]])
Y = np.array([[-1, -1]])
cosine_distances(X, Y)





from sklearn.metrics.pairwise import cosine_similarity
1-cosine_similarity(X,Y)





cosine_distances(chevy_data, chevy_data).mean()





cosine_distances(honda_data, chevy_data).mean()





from sklearn.cluster import DBSCAN
df = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/data/synthetic_clustering.csv')
df.head()


plt.scatter(df['x'], df['y'])
plt.xlabel('x')
plt.ylabel('y')
plt.show()





dbscan = DBSCAN(eps=0.1, metric=euclidean)
dbscan.fit(df)
colors = np.random.random(size=3*(dbscan.labels_.max()+1)).reshape(-1, 3)
plt.scatter(df['x'], df['y'], c=[colors[l] for l in dbscan.labels_])
plt.show()





dbscan = DBSCAN(eps=0.1, metric=cityblock)
dbscan.fit(df)
colors = np.random.random(size=3*(dbscan.labels_.max()+1)).reshape(-1, 3)
plt.scatter(df['x'], df['y'], c=[colors[l] for l in dbscan.labels_])
plt.show()





dbscan = DBSCAN(eps=0.1, metric=cosine)
dbscan.fit(df)
colors = np.random.random(size=3*(dbscan.labels_.max()+1)).reshape(-1, 3)
plt.scatter(df['x'], df['y'], c=[colors[l] for l in dbscan.labels_])
plt.show()














from sklearn.metrics import jaccard_score





df = pd.read_csv(
    'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/breast-cancer.data',
    header=None,
    names=['Class', 'age', 'menopause', 'tumor-size', 'inv-nodes', 'node-caps', 'deg-malig', 'breast', 'breast-quad', 'irradiat'])
df.head()





print(sorted(df['age'].unique()))
print(df.age.value_counts())





from sklearn.preprocessing import OneHotEncoder

OH = OneHotEncoder()


X = OH.fit_transform(df.loc[:, df.columns != 'age']).toarray()
print(f"By using onehot encoding, we obtained a 2d array with shape {X.shape} that only has value 0 and 1 ")





X30to39 = X[df[df.age == '30-39'].index]
X60to69 = X[df[df.age == '60-69'].index]

X30to39.shape, X60to69.shape





avg_distance(X30to39, X30to39, jaccard_score)





avg_distance(X60to69, X60to69, jaccard_score)





avg_distance(X30to39, X60to69, jaccard_score)











# Find the jaccard distance between the words in the following two sentences:
sentence1 = 'Hello everyone and welcome to distance metrics'
sentence2 = 'Hello world and welcome to distance metrics'


# # TODO
# ans = # TODO








# Find the absolute value of the difference between the euclidean and manhattan distances of the two 3D points:
p1 = np.array([4, -3, 1])
p2 = np.array([-5, 1, -7])


euclidean = # TODO
manhattan = # TODO
ans = # TODO








# Find the cosine distance between the following two points:
p1 = np.array([1, 2, 3]).reshape(1, -1)
p2 = np.array([-2, -4, -6]).reshape(1, -1)


ans = # TODO











X1 = np.arange(8).reshape(4, 2)
X2 = np.arange(8)[::-1].reshape(4, 2)
print(f'X1:\n{X1}')
print(f'X2:\n{X2}')


paired_euclidean = # TODO
paired_manhattan = # TODO
























