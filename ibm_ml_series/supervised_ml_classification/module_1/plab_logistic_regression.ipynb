{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "prev_pub_hash": "823be9dfebdf61764ae7367bc85d643377b068ca0c838f8bce0586628d29f3f5"
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n    </a>\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# **Logistic Regression**\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Estimated time needed: **30** minutes\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In this lab, you will learn about and get hands-on practice with the logistic regression model, a popular and effective classification model. Understanding logistic regression and being able to apply it to classification tasks is essential because logistic regression models form the fundamentals of neural networks.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "We will use a real-world dataset that contains detailed nutrition information about food items for people with diabetes. The objective is to classify whether a diabetic patient should choose More Often, Less Often, or In Moderation for a specific food item based on the nutrition information in the dataset.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Objectives\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "After completing this lab you will be able to:\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "*   Preprocess and generate training and testing datasets\n*   Train and fine-tune logistic regression models\n*   Interpret trained logistic regression models\n*   Evaluate trained logistic regression models\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "***\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Prepare and setup lab environment\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n# !mamba install -qy pandas==1.3.3 numpy==1.21.2 ipywidgets==7.4.2 scipy==7.4.2 tqdm==4.62.3 matplotlib==3.5.0 seaborn==0.9.0\n# Note: If your environment doesn't support \"!mamba install\", use \"!pip install\"",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import piplite as pl\nawait pl.install(['numpy','pandas','scikit-learn','seaborn'])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler\nfrom sklearn.model_selection import train_test_split, learning_curve\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix,ConfusionMatrixDisplay\nfrom sklearn.metrics import precision_recall_fscore_support, precision_score, recall_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "Matplotlib is building the font cache; this may take a moment.\n"
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "# also set a random state\nrs = 123",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": "### Exploratory Data Analysis(EDA) and Feature Engineering\nBefore we get to the model implementation, it is essential to examine the dataset and carefully select the features that will serve as inputs for the model..\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Load and explore the dataset\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "First, let's load the dataset as a `Pandas` dataframe and conduct some basic EDA tasks on it.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pyodide_http as ph\nph.patch_all()\ndataset_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML241EN-SkillsNetwork/labs/datasets/food_items.csv\"\nfood_df = pd.read_csv(dataset_url)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": "And, let's quickly check its column types.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "food_df.dtypes",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Calories               float64\nTotal Fat                int64\nSaturated Fat          float64\nMonounsaturated Fat    float64\nPolyunsaturated Fat    float64\nTrans Fat              float64\nCholesterol              int64\nSodium                 float64\nTotal Carbohydrate     float64\nDietary Fiber          float64\nSugars                 float64\nSugar Alcohol            int64\nProtein                float64\nVitamin A                int64\nVitamin C                int64\nCalcium                  int64\nIron                     int64\nclass                   object\ndtype: object"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": "Print the first ten food items:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "food_df.head(10)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   Calories  Total Fat  Saturated Fat  Monounsaturated Fat  \\\n0     149.0          0            0.0                  0.0   \n1     123.0          0            0.0                  0.0   \n2     150.0          0            0.0                  0.0   \n3     110.0          0            0.0                  0.0   \n4     143.0          0            0.0                  0.0   \n5     110.0          0            0.0                  0.0   \n6     142.0          0            0.0                  0.0   \n7     102.0          0            0.0                  0.0   \n8     145.0          0            0.0                  0.0   \n9     171.0          0            0.0                  0.0   \n\n   Polyunsaturated Fat  Trans Fat  Cholesterol  Sodium  Total Carbohydrate  \\\n0                  0.0        0.0            0     9.0                 9.8   \n1                  0.0        0.0            0     5.0                 6.6   \n2                  0.0        0.0            0     4.0                11.4   \n3                  0.0        0.0            0     6.0                 7.0   \n4                  0.0        0.0            0     7.0                13.1   \n5                  0.0        0.0            0     6.0                 7.0   \n6                  0.0        0.0            0    12.0                10.6   \n7                  0.0        0.0            0    13.0                 5.0   \n8                  0.0        0.0            0    17.0                11.0   \n9                  0.0        0.0            0     8.0                13.7   \n\n   Dietary Fiber  Sugars  Sugar Alcohol  Protein  Vitamin A  Vitamin C  \\\n0            0.0     0.0              0      1.3          0          0   \n1            0.0     0.0              0      0.8          0          0   \n2            0.0     0.0              0      1.3          0          0   \n3            0.0     0.0              0      0.8          0          0   \n4            0.0     0.0              0      1.0          0          0   \n5            0.0     0.0              0      0.8          0          0   \n6            0.0     0.0              0      1.2          0          0   \n7            0.0     0.0              0      0.7          0          0   \n8            0.0     0.0              0      1.2          0          0   \n9            0.0     0.0              0      2.5          0          0   \n\n   Calcium  Iron            class  \n0        0     0  'In Moderation'  \n1        0     0  'In Moderation'  \n2        0     0  'In Moderation'  \n3        0     0  'In Moderation'  \n4        0     0  'In Moderation'  \n5        0     0  'In Moderation'  \n6        0     0  'In Moderation'  \n7        0     0  'In Moderation'  \n8        0     0  'In Moderation'  \n9        0     0  'In Moderation'  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Calories</th>\n      <th>Total Fat</th>\n      <th>Saturated Fat</th>\n      <th>Monounsaturated Fat</th>\n      <th>Polyunsaturated Fat</th>\n      <th>Trans Fat</th>\n      <th>Cholesterol</th>\n      <th>Sodium</th>\n      <th>Total Carbohydrate</th>\n      <th>Dietary Fiber</th>\n      <th>Sugars</th>\n      <th>Sugar Alcohol</th>\n      <th>Protein</th>\n      <th>Vitamin A</th>\n      <th>Vitamin C</th>\n      <th>Calcium</th>\n      <th>Iron</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>149.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>9.0</td>\n      <td>9.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>'In Moderation'</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>123.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>5.0</td>\n      <td>6.6</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>'In Moderation'</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>150.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>11.4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>'In Moderation'</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>110.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>'In Moderation'</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>143.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>7.0</td>\n      <td>13.1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>'In Moderation'</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>110.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>'In Moderation'</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>142.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>12.0</td>\n      <td>10.6</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1.2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>'In Moderation'</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>102.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>13.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>'In Moderation'</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>145.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>17.0</td>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1.2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>'In Moderation'</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>171.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>8.0</td>\n      <td>13.7</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>2.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>'In Moderation'</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": "food_df['class'].value_counts()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "class\n'In Moderation'    6649\n'Less Often'       5621\n'More Often'        990\nName: count, dtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": "Get the row entries with col 0 to -1 (16).\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "feature_cols = list(food_df.columns[:-1])\nfeature_cols",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['Calories',\n 'Total Fat',\n 'Saturated Fat',\n 'Monounsaturated Fat',\n 'Polyunsaturated Fat',\n 'Trans Fat',\n 'Cholesterol',\n 'Sodium',\n 'Total Carbohydrate',\n 'Dietary Fiber',\n 'Sugars',\n 'Sugar Alcohol',\n 'Protein',\n 'Vitamin A',\n 'Vitamin C',\n 'Calcium',\n 'Iron']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": "Obtain descriptive statistics:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "food_df.describe()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "           Calories     Total Fat  Saturated Fat  Monounsaturated Fat  \\\ncount  13260.000000  13260.000000   13260.000000         13260.000000   \nmean     133.861086      4.475264       1.450617             0.338069   \nstd       94.227650      5.386340       2.410318             1.345852   \nmin        0.000000      0.000000       0.000000             0.000000   \n25%       70.000000      0.000000       0.000000             0.000000   \n50%      120.000000      3.000000       0.500000             0.000000   \n75%      180.000000      7.000000       2.000000             0.000000   \nmax     2210.000000     43.000000      22.000000            40.000000   \n\n       Polyunsaturated Fat     Trans Fat   Cholesterol        Sodium  \\\ncount         13260.000000  13260.000000  13260.000000  13260.000000   \nmean              0.254660      0.047459      8.857692    241.867142   \nstd               2.230586      0.321402     20.976530    272.284363   \nmin               0.000000      0.000000      0.000000      0.000000   \n25%               0.000000      0.000000      0.000000     40.000000   \n50%               0.000000      0.000000      0.000000    135.000000   \n75%               0.000000      0.000000     10.000000    370.000000   \nmax             235.000000     11.000000    450.000000   2431.000000   \n\n       Total Carbohydrate  Dietary Fiber        Sugars  Sugar Alcohol  \\\ncount        13260.000000   13260.000000  13260.000000   13260.000000   \nmean            18.232020       1.602971      6.645234       0.117949   \nstd             14.786316       3.363879      8.328465       1.121529   \nmin              0.000000       0.000000      0.000000       0.000000   \n25%              5.000000       0.000000      0.000000       0.000000   \n50%             17.000000       1.000000      3.000000       0.000000   \n75%             27.000000       2.000000     11.000000       0.000000   \nmax            270.000000     305.000000    115.000000      31.000000   \n\n            Protein     Vitamin A     Vitamin C       Calcium          Iron  \ncount  13260.000000  13260.000000  13260.000000  13260.000000  13260.000000  \nmean       4.661333      6.287632      6.741855      5.175264      5.235671  \nstd        5.611143     18.374191     23.785100      8.779637      9.119459  \nmin        0.000000      0.000000      0.000000      0.000000      0.000000  \n25%        1.000000      0.000000      0.000000      0.000000      0.000000  \n50%        3.000000      0.000000      0.000000      2.000000      2.000000  \n75%        7.000000      6.000000      2.000000      6.000000      8.000000  \nmax       70.000000    622.000000   1000.000000    110.000000    170.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Calories</th>\n      <th>Total Fat</th>\n      <th>Saturated Fat</th>\n      <th>Monounsaturated Fat</th>\n      <th>Polyunsaturated Fat</th>\n      <th>Trans Fat</th>\n      <th>Cholesterol</th>\n      <th>Sodium</th>\n      <th>Total Carbohydrate</th>\n      <th>Dietary Fiber</th>\n      <th>Sugars</th>\n      <th>Sugar Alcohol</th>\n      <th>Protein</th>\n      <th>Vitamin A</th>\n      <th>Vitamin C</th>\n      <th>Calcium</th>\n      <th>Iron</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>13260.000000</td>\n      <td>13260.000000</td>\n      <td>13260.000000</td>\n      <td>13260.000000</td>\n      <td>13260.000000</td>\n      <td>13260.000000</td>\n      <td>13260.000000</td>\n      <td>13260.000000</td>\n      <td>13260.000000</td>\n      <td>13260.000000</td>\n      <td>13260.000000</td>\n      <td>13260.000000</td>\n      <td>13260.000000</td>\n      <td>13260.000000</td>\n      <td>13260.000000</td>\n      <td>13260.000000</td>\n      <td>13260.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>133.861086</td>\n      <td>4.475264</td>\n      <td>1.450617</td>\n      <td>0.338069</td>\n      <td>0.254660</td>\n      <td>0.047459</td>\n      <td>8.857692</td>\n      <td>241.867142</td>\n      <td>18.232020</td>\n      <td>1.602971</td>\n      <td>6.645234</td>\n      <td>0.117949</td>\n      <td>4.661333</td>\n      <td>6.287632</td>\n      <td>6.741855</td>\n      <td>5.175264</td>\n      <td>5.235671</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>94.227650</td>\n      <td>5.386340</td>\n      <td>2.410318</td>\n      <td>1.345852</td>\n      <td>2.230586</td>\n      <td>0.321402</td>\n      <td>20.976530</td>\n      <td>272.284363</td>\n      <td>14.786316</td>\n      <td>3.363879</td>\n      <td>8.328465</td>\n      <td>1.121529</td>\n      <td>5.611143</td>\n      <td>18.374191</td>\n      <td>23.785100</td>\n      <td>8.779637</td>\n      <td>9.119459</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>70.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>40.000000</td>\n      <td>5.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>120.000000</td>\n      <td>3.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>135.000000</td>\n      <td>17.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>180.000000</td>\n      <td>7.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>10.000000</td>\n      <td>370.000000</td>\n      <td>27.000000</td>\n      <td>2.000000</td>\n      <td>11.000000</td>\n      <td>0.000000</td>\n      <td>7.000000</td>\n      <td>6.000000</td>\n      <td>2.000000</td>\n      <td>6.000000</td>\n      <td>8.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2210.000000</td>\n      <td>43.000000</td>\n      <td>22.000000</td>\n      <td>40.000000</td>\n      <td>235.000000</td>\n      <td>11.000000</td>\n      <td>450.000000</td>\n      <td>2431.000000</td>\n      <td>270.000000</td>\n      <td>305.000000</td>\n      <td>115.000000</td>\n      <td>31.000000</td>\n      <td>70.000000</td>\n      <td>622.000000</td>\n      <td>1000.000000</td>\n      <td>110.000000</td>\n      <td>170.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": "As we can see from the above output, this dataset contains 17 nutrient categories about each food item. These categories include Calories, Total Fat, Protein, Sugar, etc., and are listed as numeric variables. As such, we only need to scale them for training our logistic regression model so that we can compare our feature coefficients directly. This will be done under the feature engineering section.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Next, let's check the target variable in the `class` column to see the label values and their distribution.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# # Get the row entries with the last col 'class'\nfood_df.iloc[:, -1].value_counts(normalize=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "class\n'In Moderation'    0.501433\n'Less Often'       0.423906\n'More Often'       0.074661\nName: proportion, dtype: float64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": "food_df.iloc[:, -1].value_counts().plot.bar(color=['brown','green','blue'])",
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<Axes: xlabel='class'>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": "As we can see from the bar chart above, this dataset has three classes: `In Moderation`, `Less Often`, and `More Often`. The three labels are imbalanced. For diabetic patients, most food items are in the In Moderation and Less Often categories. This makes diabetes diet management very hard, so we could build a machine learning model to help patients choose their food.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "We have three labels meaning our logistic regression model will be multinomial with three classes.\n\nA multinomial logistic regression is a generalized logistic regression model which generates a probability distribution over all classes, based on the logits or exponentiated log-odds calculated for each class (usually more than two).\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Also note that a multinomial logistic regression model is different from the `one-vs-rest` binary logistic regression. For `one-vs-rest` schema, you need to train an independent classifier for each class. For example, you need a `More Often` classifier to differentiate a food item between `More Often` and `Not More Often` (or, `In Moderation` and `Less Often`).\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Feature Engineering\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Now you should have some basic understanding about the food dataset. Next, let's process the raw dataset and construct input data `X` and label/output `y` for logistic regression model training.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X_raw = food_df.iloc[:, :-1]\ny_raw = food_df.iloc[:, -1]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": "X_raw.shape, y_raw.shape",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "((13260, 17), (13260,))"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "source": "Fortunately, all feature columns are numeric so we just need to scale them. Here we use the `MinMaxScaler` provided by `sklearn` for scaling.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "scaler = MinMaxScaler()  # normalization",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": "# before normalization\nX_raw.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   Calories  Total Fat  Saturated Fat  Monounsaturated Fat  \\\n0     149.0          0            0.0                  0.0   \n1     123.0          0            0.0                  0.0   \n2     150.0          0            0.0                  0.0   \n3     110.0          0            0.0                  0.0   \n4     143.0          0            0.0                  0.0   \n\n   Polyunsaturated Fat  Trans Fat  Cholesterol  Sodium  Total Carbohydrate  \\\n0                  0.0        0.0            0     9.0                 9.8   \n1                  0.0        0.0            0     5.0                 6.6   \n2                  0.0        0.0            0     4.0                11.4   \n3                  0.0        0.0            0     6.0                 7.0   \n4                  0.0        0.0            0     7.0                13.1   \n\n   Dietary Fiber  Sugars  Sugar Alcohol  Protein  Vitamin A  Vitamin C  \\\n0            0.0     0.0              0      1.3          0          0   \n1            0.0     0.0              0      0.8          0          0   \n2            0.0     0.0              0      1.3          0          0   \n3            0.0     0.0              0      0.8          0          0   \n4            0.0     0.0              0      1.0          0          0   \n\n   Calcium  Iron  \n0        0     0  \n1        0     0  \n2        0     0  \n3        0     0  \n4        0     0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Calories</th>\n      <th>Total Fat</th>\n      <th>Saturated Fat</th>\n      <th>Monounsaturated Fat</th>\n      <th>Polyunsaturated Fat</th>\n      <th>Trans Fat</th>\n      <th>Cholesterol</th>\n      <th>Sodium</th>\n      <th>Total Carbohydrate</th>\n      <th>Dietary Fiber</th>\n      <th>Sugars</th>\n      <th>Sugar Alcohol</th>\n      <th>Protein</th>\n      <th>Vitamin A</th>\n      <th>Vitamin C</th>\n      <th>Calcium</th>\n      <th>Iron</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>149.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>9.0</td>\n      <td>9.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>123.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>5.0</td>\n      <td>6.6</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>150.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>11.4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>110.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>143.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>7.0</td>\n      <td>13.1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": "# Scaling the raw input features\nX = scaler.fit_transform(X_raw)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": "X[:5]",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[0.06742081, 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.00370218, 0.0362963 , 0.        ,\n        0.        , 0.        , 0.01857143, 0.        , 0.        ,\n        0.        , 0.        ],\n       [0.05565611, 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.00205677, 0.02444444, 0.        ,\n        0.        , 0.        , 0.01142857, 0.        , 0.        ,\n        0.        , 0.        ],\n       [0.0678733 , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.00164541, 0.04222222, 0.        ,\n        0.        , 0.        , 0.01857143, 0.        , 0.        ,\n        0.        , 0.        ],\n       [0.04977376, 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.00246812, 0.02592593, 0.        ,\n        0.        , 0.        , 0.01142857, 0.        , 0.        ,\n        0.        , 0.        ],\n       [0.06470588, 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.00287947, 0.04851852, 0.        ,\n        0.        , 0.        , 0.01428571, 0.        , 0.        ,\n        0.        , 0.        ]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": "Let's check the scaled feature value range:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(f\"The range of feature inputs are within {X.min()} to {X.max()}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "The range of feature inputs are within 0.0 to 1.0\n"
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "markdown",
      "source": "For the target variable `y`, let's use the `LabelEncoder` provided by `sklearn` to encode its three class values.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "label_encoder = LabelEncoder() # for dependent variable (y)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 19
    },
    {
      "cell_type": "code",
      "source": "y_raw.values.shape",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 20,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(13260,)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "source": "y_raw.values.ravel() # convert 2D arrays to 1D array",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 21,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([\"'In Moderation'\", \"'In Moderation'\", \"'In Moderation'\", ...,\n       \"'In Moderation'\", \"'In Moderation'\", \"'In Moderation'\"],\n      dtype=object)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 21
    },
    {
      "cell_type": "code",
      "source": "h = label_encoder.fit_transform(y_raw.values)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 22
    },
    {
      "cell_type": "code",
      "source": "# Encode the target variable\ny = label_encoder.fit_transform(y_raw.values.ravel()) \n# in this case not require `.ravel()'",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 23
    },
    {
      "cell_type": "code",
      "source": "(h == y).any()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "np.True_"
          },
          "metadata": {}
        }
      ],
      "execution_count": 25
    },
    {
      "cell_type": "markdown",
      "source": "The encoded target variable will only contain values `0=In Moderation`, `1=Less Often`, `2=More Often`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "np.unique(y, return_counts=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 26,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(array([0, 1, 2]), array([6649, 5621,  990]))"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "markdown",
      "source": "|values | counts |\n|-------|--------|\n| 0 | 6649 |\n| 1 | 5621 |\n| 2 |  990 |\n\n\n**0** = `In Moderation`  \n**1** = `Less Often`  \n**2** = `More Often`",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Train logistic regression models\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "First, let's split the dataset into a training and a testing dataset. Training dataset will be used to train and (maybe) tune models, and testing dataset will be used to evaluate the models. Note that you may also split the training dataset into train and validation sets where the validation dataset is only used to tune the model and to set the model parameters.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# First, let's split the training and testing dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state = rs)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 27
    },
    {
      "cell_type": "markdown",
      "source": "```python\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state = rs)\n```  \n`stratify=y` is used in this code since value counts in 'y' are not balanced. It is significant for large datasets.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Let's look at the shapes of the split datasets:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# check value counts in y_train\nprint(\"y_train:\", np.unique(y_train, return_counts=True))\n# check value counts in y_test\nprint(\"y_test:\", np.unique(y_test, return_counts=True))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "y_train: (array([0, 1, 2]), array([5319, 4497,  792]))\ny_test: (array([0, 1, 2]), array([1330, 1124,  198]))\n"
        }
      ],
      "execution_count": 28
    },
    {
      "cell_type": "code",
      "source": "# Let's try without stratification\nH_train, H_test, a_train, a_test = train_test_split(X, y, test_size=0.2, random_state=rs)\nprint(\"a_train:\", np.unique(a_train, return_counts=True))\nprint(\"a_test:\", np.unique(a_test, return_counts=True))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "a_train: (array([0, 1, 2]), array([5305, 4512,  791]))\na_test: (array([0, 1, 2]), array([1344, 1109,  199]))\n"
        }
      ],
      "execution_count": 29
    },
    {
      "cell_type": "code",
      "source": "print(f\"Training dataset shape, X_train: {X_train.shape}, y_train: {y_train.shape}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Training dataset shape, X_train: (10608, 17), y_train: (10608,)\n"
        }
      ],
      "execution_count": 30
    },
    {
      "cell_type": "code",
      "source": "print(f\"Testing dataset shape, X_test: {X_test.shape}, y_test: {y_test.shape}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Testing dataset shape, X_test: (2652, 17), y_test: (2652,)\n"
        }
      ],
      "execution_count": 31
    },
    {
      "cell_type": "markdown",
      "source": "OK, now we have the training and testing datasets ready, let's start the model training task.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "We first define a `sklearn.linear_model.LogisticRegression` model with the following arguments, you can check the comment for each argument for what it means.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# L2 penalty to shrink coefficients without removing any features from the model\npenalty= 'l2'\n\n# Our classification problem is multinomial coz y values has [0,1,2]\nmulti_class = 'multinomial'\n\n# Use lbfgs for L2 penalty and multinomial classes\nsolver = 'lbfgs'\n\n# Max iteration = 1000\nmax_iter = 1000",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 32
    },
    {
      "cell_type": "markdown",
      "source": "**From ChatGPT**:  \nThe `lbfgs` (Limited-memory Broyden–Fletcher–Goldfarb–Shanno) solver is an optimization algorithm used in logistic regression to find the best model parameters. It is particularly useful for small to medium-sized datasets.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Define a logistic regression model with above arguments\nl2_model = LogisticRegression(random_state=rs, penalty=penalty, \n                              multi_class=multi_class, solver=solver, \n                              max_iter=max_iter)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 33
    },
    {
      "cell_type": "markdown",
      "source": "Let's train the model with training input data `X_train` and labels `y_train`:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "l2_model.fit(X_train, y_train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
        },
        {
          "execution_count": 34,
          "output_type": "execute_result",
          "data": {
            "text/plain": "LogisticRegression(max_iter=1000, multi_class='multinomial', random_state=123)",
            "text/html": "<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;, random_state=123)</pre></div> </div></div></div></div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 34
    },
    {
      "cell_type": "code",
      "source": "l2_preds = l2_model.predict(X_test)\nnp.unique(l2_preds)",
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "outputs": [
        {
          "execution_count": 35,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([0, 1, 2])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 35
    },
    {
      "cell_type": "code",
      "source": "label_encoder.inverse_transform(l2_preds)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 36,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([\"'Less Often'\", \"'Less Often'\", \"'In Moderation'\", ...,\n       \"'In Moderation'\", \"'In Moderation'\", \"'Less Often'\"], dtype=object)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 36
    },
    {
      "cell_type": "code",
      "source": "# Checking the results by comparing\npd.DataFrame({'test_value': label_encoder.inverse_transform(y_test), \n              'pred_value': label_encoder.inverse_transform(l2_preds)}).sample(10)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 37,
          "output_type": "execute_result",
          "data": {
            "text/plain": "           test_value       pred_value\n803      'Less Often'  'In Moderation'\n2439     'Less Often'     'Less Often'\n2304     'Less Often'  'In Moderation'\n1239     'Less Often'     'Less Often'\n1632  'In Moderation'  'In Moderation'\n1366     'Less Often'     'Less Often'\n163      'Less Often'  'In Moderation'\n898      'More Often'  'In Moderation'\n505   'In Moderation'  'In Moderation'\n265      'More Often'  'In Moderation'",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test_value</th>\n      <th>pred_value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>803</th>\n      <td>'Less Often'</td>\n      <td>'In Moderation'</td>\n    </tr>\n    <tr>\n      <th>2439</th>\n      <td>'Less Often'</td>\n      <td>'Less Often'</td>\n    </tr>\n    <tr>\n      <th>2304</th>\n      <td>'Less Often'</td>\n      <td>'In Moderation'</td>\n    </tr>\n    <tr>\n      <th>1239</th>\n      <td>'Less Often'</td>\n      <td>'Less Often'</td>\n    </tr>\n    <tr>\n      <th>1632</th>\n      <td>'In Moderation'</td>\n      <td>'In Moderation'</td>\n    </tr>\n    <tr>\n      <th>1366</th>\n      <td>'Less Often'</td>\n      <td>'Less Often'</td>\n    </tr>\n    <tr>\n      <th>163</th>\n      <td>'Less Often'</td>\n      <td>'In Moderation'</td>\n    </tr>\n    <tr>\n      <th>898</th>\n      <td>'More Often'</td>\n      <td>'In Moderation'</td>\n    </tr>\n    <tr>\n      <th>505</th>\n      <td>'In Moderation'</td>\n      <td>'In Moderation'</td>\n    </tr>\n    <tr>\n      <th>265</th>\n      <td>'More Often'</td>\n      <td>'In Moderation'</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 37
    },
    {
      "cell_type": "markdown",
      "source": "Because we may need to evaluate the model multiple times with different model hyper parameters, here we define an utility method to take the ground truths `y_test` and the predictions `preds`, and return a Python `dict` with `accuracy`, `recall`, `precision`, and `f1score`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Test defined function first\nresults = {}\nresults['accuracy'] = accuracy_score(y_test, l2_preds)\nx, y, z = 'precision', 'recall', 'f1_score'\nresults[x], results[y], results[z], _ = precision_recall_fscore_support(y_test, l2_preds)\n\nresults",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 39,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'accuracy': 0.7748868778280543,\n 'precision': array([0.73035827, 0.83553299, 0.92105263]),\n 'recall': array([0.87368421, 0.73220641, 0.35353535]),\n 'f1_score': array([0.79561794, 0.78046468, 0.51094891])}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 39
    },
    {
      "cell_type": "code",
      "source": "def evaluate_metrics(yt, yp):\n    results_pos = {}\n    results_pos['accuracy'] = accuracy_score(yt, yp)\n    precision, recall, f_beta, _ = precision_recall_fscore_support(yt, yp)\n    results_pos['recall'] = recall\n    results_pos['precision'] = precision\n    results_pos['f1_score'] = f_beta\n    return results_pos",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 44
    },
    {
      "cell_type": "code",
      "source": "evaluate_metrics(y_test, l2_preds)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 45,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'accuracy': 0.7748868778280543,\n 'recall': array([0.87368421, 0.73220641, 0.35353535]),\n 'precision': array([0.73035827, 0.83553299, 0.92105263]),\n 'f1_score': array([0.79561794, 0.78046468, 0.51094891])}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 45
    },
    {
      "cell_type": "markdown",
      "source": "As we can see from  the above evaluation results, the logistic regression model has relatively good performance on this multinomial classification task. The overall accuracy is around `0.77` and the f1score is around `0.8`. Note that for `recall`, `precision`, and `f1_score`, we output the values for each class to see how the model performs on an individual class. And, we can see from the results, the recall for `class=2` (More often) is not very good. This is actually a common problem called imbalanced classification challenge. We will introduce solution to this problem later in this course.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Next, let's try defining another logistic regression model with l1 penality this time, to see if our classification performance would be improved.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# L1 penalty to shrink coefficients without removing any features from the model\npenalty= 'l1'\n# Our classification problem is multinomial\nmulti_class = 'multinomial'\n# Use saga for L1 penalty and multinomial classes\nsolver = 'saga'\n# Max iteration = 1000\nmax_iter = 1000",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Then we define another logistic regression model with above arguments using l1 penality and related solver.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Define a logistic regression model with above arguments\nl1_model = LogisticRegression(random_state=rs, penalty=penalty, multi_class=multi_class, solver=solver, max_iter = 1000)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can start to train the new `l1_model` with the new taining dataset.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "l1_model.fit(X_train, y_train)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "And, make predictions using the input in the test dataset.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "l1_preds = l1_model.predict(X_test)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can also check the class probability distribution using the `predict_proba` function. For example, we want to see the probabilities of belonging to each class for the first instance in the test dataset:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "odd_ratios = l1_model.predict_proba(X_test[:1, :])[0]\nodd_ratios",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "We can see that  Class 1 has the largest probability 0.96. As such, the model prediction for this instance will be class `1` and this is the same as the `predict` method.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "l1_model.predict(X_test[:1, :])[0]",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Given the true labels (`y_test`) and predictions, we can evaluate the model performance by calling the utility `evaluate_metrics`  method.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "evaluate_metrics(y_test, l1_preds)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Now, we can see this logistic regression with l1 penalty has much better performance than l2. One possible reason is that l1 penalty may remove some correlated feature variables by shrinking their coefficents to zero. As such, the model is much simplified to avoid overfitting on the training data and better aligned with the logistic regression assumption that all features should be independent.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Confusion Matrix\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "We can also plot the confusion matrix based on the true labels and predictions using the `confusion_matrix` method provided by `sklearn`,\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "cf = confusion_matrix(y_test, l1_preds, normalize='true')",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "and easily visualize it using a heatmap method provided by `seaborn`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "sns.set_context('talk')\ndisp = ConfusionMatrixDisplay(confusion_matrix=cf,display_labels=l1_model.classes_)\ndisp.plot()\nplt.show()",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Interpret logistic regression models\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "One way to interpret logistic regression models is by analyzing feature coefficients. Although it may not be as effective as the regular linear regression models because the logistic regression model has a sigmoid function, we can still get a sense for the importance or impact of each feature.  \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "We can check the coefficients for logistic regression model using its `coef_` attribute:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "l1_model.coef_",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "The `coef_` is a coefficients list with three elements, one element is the actual coefficent for class 0, 1, 2. To better analyze the coefficients, let's use three utility methods to sort and visualize them.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Extract and sort feature coefficients\ndef get_feature_coefs(regression_model, label_index, columns):\n    coef_dict = {}\n    for coef, feat in zip(regression_model.coef_[label_index, :], columns):\n        if abs(coef) >= 0.01:\n            coef_dict[feat] = coef\n    # Sort coefficients\n    coef_dict = {k: v for k, v in sorted(coef_dict.items(), key=lambda item: item[1])}\n    return coef_dict\n\n# Generate bar colors based on if value is negative or positive\ndef get_bar_colors(values):\n    color_vals = []\n    for val in values:\n        if val <= 0:\n            color_vals.append('r')\n        else:\n            color_vals.append('g')\n    return color_vals\n\n# Visualize coefficients\ndef visualize_coefs(coef_dict):\n    features = list(coef_dict.keys())\n    values = list(coef_dict.values())\n    y_pos = np.arange(len(features))\n    color_vals = get_bar_colors(values)\n    plt.rcdefaults()\n    fig, ax = plt.subplots()\n    ax.barh(y_pos, values, align='center', color=color_vals)\n    ax.set_yticks(y_pos)\n    ax.set_yticklabels(features)\n    # labels read top-to-bottom\n    ax.invert_yaxis()  \n    ax.set_xlabel('Feature Coefficients')\n    ax.set_title('')\n    plt.show()",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Then, let's visualize the sorted coefficient for class 1, the `Less Often` class: \n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Get the coefficents for Class 1, Less Often\ncoef_dict = get_feature_coefs(l1_model, 1, feature_cols)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "visualize_coefs(coef_dict)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "As we can see, unhealthy nutrients such as Saturated Fat, Sugars, Cholesterol, Total Fat, etc., have high positive coefficients. Food items containing unhealthy nutrients will have higher coeficients and will be more likely to be categorized in the 'Less Often' class.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Next, let's see the coefficents for Class 2, `More Often`:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Coefficients for Class 2\ncoef_dict = get_feature_coefs(l1_model, 2, feature_cols)\nvisualize_coefs(coef_dict)",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Conversely, if a food item has a high amount of calories, total carbohydrates, and total fat, then it is unlikely to be categorized in the 'More Often' class.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Coding Exercise: Train and evaluate a logistic regression model with elastic-net penality\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Now, it's your turn to walk through the end-to-end process of defining, building, evaluating, and interpreting a logistic regression model.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Define a logistic regression with elastic-net penality\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Type your code here\n# HINT: sklearn only support saga solver for elastic-net penality\n# and you need to set another l1_ratio to be within 0 < l1_ratio <1, in order to actually use elastic-net\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Train the model with training data\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Type your code here\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Evaluate the model using accuracy, precision, recall, and F1score\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Type your code here\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Plot confusion matrix\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Type your code here\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Interpret the model by analysing its coefficients\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Type your code here\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for a sample solution</summary>\n\n```python\n# elasticnet penalty to shrink coefficients without removing any features from the model\npenalty= 'elasticnet'\n# Our classification problem is multinomial\nmulti_class = 'multinomial'\n# Use saga for L1 penalty and multinomial classes\nsolver = 'saga'\n# Max iteration = 1000\nmax_iter = 1000\n# l1_ratio\nl1_ratio = 0.1\n\n# Define a elastic-net model\nen_model = LogisticRegression(random_state=rs, penalty=penalty, multi_class=multi_class, solver=solver, max_iter = 1000, l1_ratio=l1_ratio)\nen_model.fit(X_train, y_train)\n# Make predictions\npreds = en_model.predict(X_test)\n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Next steps\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Great! Now you have learned about and practiced applying a logistic regression model to solve a real-world food classification problem for diabetic patients. You also learned how to evaluate and interpret the trained logistic regression models.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Next, you will be learning other popular classification models with different structures, assumptions, cost functions, and application scenarios.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Authors\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "[Yan Luo](https://www.linkedin.com/in/yan-luo-96288783/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML241ENSkillsNetwork31576874-2021-01-01)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Other Contributors\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<!--## Change Log--!>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<!--| Date (YYYY-MM-DD) | Version | Changed By | Change Description          |\n| ----------------- | ------- | ---------- | --------------------------- |\n| 2021-10-25        | 1.0     | Yan        | Created the initial version |\n--!>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Copyright © 2021 IBM Corporation. All rights reserved.\n",
      "metadata": {}
    }
  ]
}