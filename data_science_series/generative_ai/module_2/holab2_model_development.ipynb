{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"Skills Network Logo\">\n    </a>\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Test Environment for Generative AI classroom labs\n\nThis lab provides a test environment for the codes generated using the Generative AI classroom.\n\nFollow the instructions below to set up this environment for further use.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In this lab, you will learn how to use generative AI to create Python codes that can:\n\n1. Use `linear regression` in **one variable** to fit the parameters to a model\n2. Use `linear regression` in **multiple variables** to fit the parameters to a model\n3. Use `polynomial regression` in a **single variable** to fit the parameters to a model\n4. Create a pipeline for performing `linear regression` using multiple features in polynomial scaling\n5. Use the **grid search** with `cross-validation` and `ridge regression` to create a model with optimum hyperparameters",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Setup\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Install required libraries\n\nIn case of a requirement of installing certain python libraries for use in your task, you may do so as shown below.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "%pip install seaborn\nimport piplite\n\nawait piplite.install(['nbformat', 'plotly'])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": "### Dataset URL from the GenAI lab\nUse the URL provided in the GenAI lab in the cell below. \n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "URL = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-Coursera/laptop_pricing_dataset_mod2.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": "### Downloading the dataset\n\nExecute the following code to download the dataset in to the interface.\n\n> Please note that this step is essential in JupyterLite. If you are using a downloaded version of this notebook and running it on JupyterLabs, then you can skip this step and directly use the URL in pandas.read_csv() function to read the dataset as a dataframe\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyodide.http import pyfetch\n\nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())\n\npath = URL\n\nawait download(path, \"dataset.csv\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": "---\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\ndf = pd.read_csv('dataset.csv')",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-4-1d6c5935348d>:1: DeprecationWarning: \nPyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\nbut was not found to be installed on your system.\nIf this would cause problems for you,\nplease provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n        \n  import pandas as pd\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": "df.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   Unnamed: 0.1  Unnamed: 0 Manufacturer  Category  GPU  OS  CPU_core  \\\n0             0           0         Acer         4    2   1         5   \n1             1           1         Dell         3    1   1         3   \n2             2           2         Dell         3    1   1         7   \n3             3           3         Dell         4    2   1         5   \n4             4           4           HP         4    2   1         7   \n\n   Screen_Size_inch  CPU_frequency  RAM_GB  Storage_GB_SSD  Weight_pounds  \\\n0              14.0       0.551724       8             256        3.52800   \n1              15.6       0.689655       4             256        4.85100   \n2              15.6       0.931034       8             256        4.85100   \n3              13.3       0.551724       8             128        2.69010   \n4              15.6       0.620690       8             256        4.21155   \n\n   Price Price-binned  Screen-Full_HD  Screen-IPS_panel  \n0    978          Low               0                 1  \n1    634          Low               1                 0  \n2    946          Low               1                 0  \n3   1244          Low               0                 1  \n4    837          Low               1                 0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0.1</th>\n      <th>Unnamed: 0</th>\n      <th>Manufacturer</th>\n      <th>Category</th>\n      <th>GPU</th>\n      <th>OS</th>\n      <th>CPU_core</th>\n      <th>Screen_Size_inch</th>\n      <th>CPU_frequency</th>\n      <th>RAM_GB</th>\n      <th>Storage_GB_SSD</th>\n      <th>Weight_pounds</th>\n      <th>Price</th>\n      <th>Price-binned</th>\n      <th>Screen-Full_HD</th>\n      <th>Screen-IPS_panel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>Acer</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>5</td>\n      <td>14.0</td>\n      <td>0.551724</td>\n      <td>8</td>\n      <td>256</td>\n      <td>3.52800</td>\n      <td>978</td>\n      <td>Low</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Dell</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>15.6</td>\n      <td>0.689655</td>\n      <td>4</td>\n      <td>256</td>\n      <td>4.85100</td>\n      <td>634</td>\n      <td>Low</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>Dell</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>15.6</td>\n      <td>0.931034</td>\n      <td>8</td>\n      <td>256</td>\n      <td>4.85100</td>\n      <td>946</td>\n      <td>Low</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>Dell</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>5</td>\n      <td>13.3</td>\n      <td>0.551724</td>\n      <td>8</td>\n      <td>128</td>\n      <td>2.69010</td>\n      <td>1244</td>\n      <td>Low</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>HP</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>7</td>\n      <td>15.6</td>\n      <td>0.620690</td>\n      <td>8</td>\n      <td>256</td>\n      <td>4.21155</td>\n      <td>837</td>\n      <td>Low</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": "### Linear regression in one variable",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**AI prompt 1:**  \nWrite a Python code that performs the following tasks.\n1. Develops and trains a linear regression model that uses one attribute of a data frame as the source variable and another as a target variable.\n2. Calculate and display the MSE and R^2 values for the trained model\n  \n**Result**  \nSure! Here is a Python code that performs the tasks you mentioned:\n\n```python\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Load your data into a pandas DataFrame\ndata = pd.read_csv('your_data.csv')\n\n# Define your source and target variables\nX = data['source_variable'].values.reshape(-1, 1)\ny = data['target_variable'].values\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train the linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Calculate MSE and R^2 values\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(\"Mean Squared Error:\", mse)\nprint(\"R^2 Score:\", r2)\n```\n\nThis code will load your data, split it into training and testing sets, train a linear regression model using the source variable as the input and the target variable as the output, and then calculate and display the Mean Squared Error (MSE) and R^2 values for the trained model.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": "X = df[['CPU_frequency']]\ny = df[['Price']]\nx_train, x_test, y_train, y_test = train_test_split(X, y,\n                                                   test_size=.2,\n                                                   random_state=14)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": "model = LinearRegression()\nmodel.fit(x_train, y_train)\ny_pred = model.predict(x_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": "mse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\nprint(\"Mean Squared Error:\", mse)\nprint(\"R2 Score:\", r2)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Mean Squared Error: 377282.07458982826\nR2 Score: 0.14979264117084223\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": "### Linear Regression in Multiple Variables",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**AI prompt 2:**  \nWrite a Python code that performs the following tasks.\n1. Develops and trains a linear regression model that uses some attributes of a data frame as the source variables and one of the attributes as a target variable.\n2. Calculate and display the MSE and R^2 values for the trained model.\n  \n**Result**  \nCertainly! Here is a Python code that accomplishes the tasks you specified:\n\n```python\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Load your data into a pandas DataFrame\ndata = pd.read_csv('your_data.csv')\n\n# Define your source variables and target variable\nX = data[['source_variable1', 'source_variable2']].values\ny = data['target_variable'].values\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train the linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Calculate MSE and R^2 values\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(\"Mean Squared Error:\", mse)\nprint(\"R^2 Score:\", r2)\n```\n\nThis code will load your data, split it into training and testing sets, train a linear regression model using multiple source variables as inputs and one target variable as the output, and then calculate and display the Mean Squared Error (MSE) and R^2 values for the trained model.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X = df[[\"CPU_frequency\", \"RAM_GB\", \"Storage_GB_SSD\",\n        \"CPU_core\", \"OS\", \"GPU\", \"Category\"]]\ny = df[['Price']]\nx_train, x_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size=0.8,\n                                                    random_state=43)\nx_train.shape, x_test.shape, y_train.shape, y_test.shape",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "((47, 7), (191, 7), (47, 1), (191, 1))"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": "lr = LinearRegression()\nlr.fit(x_train, y_train)\ny_pred = lr.predict(x_test)\nprint(\"Mean Square Error:\", mean_squared_error(y_test, y_pred))\nprint(\"R2 Score:\", r2_score(y_test, y_pred))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Mean Square Error: 200688.32777900505\nR2 Score: 0.3566912736946105\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": "### Polynomial regression",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "You can explore creating a model that uses higher-order features from original attributes. Higher orders of the same feature allow better generalization on the target variable. It is called polynomial regression, and you can use Generative AI to create a code for this.\n\nAssume you are given a single attribute as the source variable and one as a target variable. You must create a model using polynomial regression for a given order. You can also make the model for different order values and compare their performance based on MSE and $R^2$ scores.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**AI prompt 3:**  \nWrite a Python code that performs the following tasks.\n1. Develops and trains multiple polynomial regression models, with orders 2, 3, and 5, that use one attribute of a data frame as the source variable and another as a target variable.\n2. Calculate and display the MSE and R^2 values for the trained models.\n3. Compare the performance of the models.\n  \n**Result**  \n\nCertainly! Here is a Python code that meets your requirements:\n\n```python\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Load your data into a pandas DataFrame\ndata = pd.read_csv('your_data.csv')\n\n# Define your source and target variables\nX = data['source_variable'].values.reshape(-1, 1)\ny = data['target_variable'].values\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train polynomial regression models with orders 2, 3, and 5\norders = [2, 3, 5]\nfor order in orders:\n    poly_features = PolynomialFeatures(degree=order)\n    X_poly_train = poly_features.fit_transform(X_train)\n    X_poly_test = poly_features.transform(X_test)\n    \n    model = LinearRegression()\n    model.fit(X_poly_train, y_train)\n    \n    y_pred = model.predict(X_poly_test)\n    \n    mse = mean_squared_error(y_test, y_pred)\n    r2 = r2_score(y_test, y_pred)\n    \n    print(f\"Polynomial Regression Model (Order {order}):\")\n    print(\"Mean Squared Error:\", mse)\n    print(\"R^2 Score:\", r2)\n    print()\n\n# Compare the performance of the models based on MSE and R^2 values\n# The model with the lowest MSE and highest R^2 score is considered the best performing model\n```\n\nThis code will load your data, split it into training and testing sets, train polynomial regression models with orders 2, 3, and 5 using the source variable as input and the target variable as output, calculate and display the Mean Squared Error (MSE) and R^2 values for each model, and then you can compare the performance of the models based on these values.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.preprocessing import PolynomialFeatures\nX = df[['CPU_frequency']]\ny = df[['Price']]\nx_train, x_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size=.2,\n                                                    random_state=24)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": "x_train.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "     CPU_frequency\n209       0.931034\n220       0.931034\n150       0.862069\n203       0.965517\n226       0.793103",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CPU_frequency</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>209</th>\n      <td>0.931034</td>\n    </tr>\n    <tr>\n      <th>220</th>\n      <td>0.931034</td>\n    </tr>\n    <tr>\n      <th>150</th>\n      <td>0.862069</td>\n    </tr>\n    <tr>\n      <th>203</th>\n      <td>0.965517</td>\n    </tr>\n    <tr>\n      <th>226</th>\n      <td>0.793103</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\n\norders = [2,3,5]\nmses = []\nr2s = []\nfor order in orders:\n    pf = PolynomialFeatures(degree=order)\n    x_pf_train = pf.fit_transform(x_train)\n    x_pf_test = pf.transform(x_test)\n    \n    lr = LinearRegression()\n    lr.fit(x_pf_train, y_train)\n    y_pred = lr.predict(x_pf_test)\n\n    mse = mean_squared_error(y_test, y_pred)\n    r2 = r2_score(y_test, y_pred)\n    mses.append(mse)\n    r2s.append(r2)\n    \n    print(f\"{order} order\\n*******\")\n    print(\"Mean Square Error:\", mse)\n    print(\"R2 Score:\", r2)\n    print()\n\n# print(mses)\n# print(r2s)\nprint(\"The best polynomial order:\", np.argmin(mses)+3 if np.argmin(mses) > 1 else np.argmin(mses)+2)\nprint(\"The worst polynomial order:\", np.argmin(r2s)+3 if np.argmin(r2s) > 1 else np.argmin(r2s)+2)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "2 order\n*******\nMean Square Error: 289080.97135422117\nR2 Score: 0.3744275363323871\n\n3 order\n*******\nMean Square Error: 265526.22990816\nR2 Score: 0.42540009799370293\n\n5 order\n*******\nMean Square Error: 228955.85281412964\nR2 Score: 0.5045385511018243\n\nThe best polynomial order: 5\nThe worst polynomial order: 2\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "source": "### Creating a Pipeline",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**AI prompt 4:**  \n\n  \n**Result**  \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Creating a Pipeline",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Pipelines are processes containing a sequence of steps that lead to creating a trained model.\n\nYou will now use the Generative AI model to create a pipeline for performing feature scaling, creating polynomial features for multiple attributes, and performing linear regression using these variables.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**AI prompt 4:**  \nWrite a Python code that performs the following tasks.\n1. Create a pipeline that performs parameter scaling, Polynomial Feature generation, and Linear regression. Use the set of multiple features as before to create this pipeline.\n2. Calculate and display the MSE and R^2 values for the trained model.\n  \n**Result**  \nSure! Here is the Python code that performs the tasks you mentioned:\n\n```python\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Assuming X_train and y_train are your training data\n# Assuming X_test and y_test are your test data\n\n# Create a pipeline\npipeline = make_pipeline(\n    StandardScaler(),\n    PolynomialFeatures(),\n    LinearRegression()\n)\n\n# Fit the pipeline on training data\npipeline.fit(X_train, y_train)\n\n# Predict on test data\ny_pred = pipeline.predict(X_test)\n\n# Calculate MSE and R^2 values\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(\"Mean Squared Error:\", mse)\nprint(\"R^2 Score:\", r2)\n```\n\nThis code creates a pipeline with parameter scaling, polynomial feature generation, and linear regression. It then fits the pipeline on the training data, predicts on the test data, and calculates the MSE and R^2 values for the trained model.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": "X = df[[\"CPU_frequency\", \"RAM_GB\", \"Storage_GB_SSD\",\n        \"CPU_core\", \"OS\", \"GPU\", \"Category\"]]\ny = df[['Price']]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 19
    },
    {
      "cell_type": "code",
      "source": "pipeline = make_pipeline(StandardScaler(), \n                         PolynomialFeatures(), \n                         LinearRegression())\npipeline.fit(x_train, y_train)\ny_pred = pipeline.predict(x_test)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "source": "print(\"Mean Square Error:\", mean_squared_error(y_test, y_pred))\nprint(\"R2 Score:\", r2_score(y_test, y_pred))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Mean Square Error: 289080.9713542206\nR2 Score: 0.37442753633238834\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 21
    },
    {
      "cell_type": "markdown",
      "source": "### Grid search and Ridge regression",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "An improved way to train your model is to use ridge regression instead of linear regression. You can use the polynomial features of multiple attributes. One of the key factors of ridge regression is using the parameter alpha as a hyperparameter for training. Using grid search, one can determine the optimum value of the hyperparameter for the given set of features. Grid search also uses cross-validation training to train and prepare the optimum model.\n\nYou can use generative AI to create the Python code to perform a grid search for the optimum ridge regression model, which uses polynomial features generated from multiple parameters.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**AI prompt 5:**  \nWrite a Python code that performs the following tasks.\n1. Use polynomial features for some of the attributes of a data frame.\n2. Perform Grid search on a ridge regression model for a set of values of hyperparameter alpha and polynomial features as input.\n3. Use cross-validation in the Grid search.\n4. Evaluate the resulting model's MSE and R^2 values.\n  \n**Result**  \nSure! Here is the Python code that performs the tasks you mentioned:\n\n```python\nimport pandas as pd\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Assuming df is your dataframe with the data\n\n# Select the attributes for which you want to create polynomial features\nselected_attributes = ['attribute1', 'attribute2']\n\n# Create polynomial features for selected attributes\npoly = PolynomialFeatures(degree=2)\ndf_poly = poly.fit_transform(df[selected_attributes])\n\n# Define the Ridge regression model\nridge = Ridge()\n\n# Define the hyperparameters for Grid search\nparam_grid = {\n    'alpha': [0.1, 1, 10],\n}\n\n# Perform Grid search with cross-validation\ngrid_search = GridSearchCV(estimator=ridge, param_grid=param_grid, cv=5)\ngrid_search.fit(df_poly, df['target_variable'])\n\n# Evaluate the resulting model\nbest_model = grid_search.best_estimator_\nmse = -cross_val_score(best_model, df_poly, df['target_variable'], scoring='neg_mean_squared_error', cv=5)\nr2 = cross_val_score(best_model, df_poly, df['target_variable'], scoring='r2', cv=5)\n\nprint(\"Mean Squared Error:\", mse.mean())\nprint(\"R^2 Score:\", r2.mean())\n```\n\nThis code creates polynomial features for selected attributes of a dataframe, performs Grid search on a Ridge regression model with specified hyperparameters and polynomial features, uses cross-validation in the Grid search, and evaluates the resulting model by calculating the MSE and R^2 values.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.linear_model import Ridge",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 22
    },
    {
      "cell_type": "code",
      "source": "X = df[[\"CPU_frequency\", \"RAM_GB\", \"Storage_GB_SSD\",\n        \"CPU_core\", \"OS\", \"GPU\", \"Category\"]]\ny = df[['Price']]\n\nh_paras = {'alpha':[0.0001,0.001,0.01, 0.1, 1, 10]}",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 36
    },
    {
      "cell_type": "code",
      "source": "pf = PolynomialFeatures(degree=2)\nridge = Ridge()\nX_pf = pf.fit_transform(X)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 43
    },
    {
      "cell_type": "code",
      "source": "grid_search = GridSearchCV(ridge, h_paras, cv=5)\ngrid_search.fit(X_pf, y)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 44,
          "output_type": "execute_result",
          "data": {
            "text/plain": "GridSearchCV(cv=5, estimator=Ridge(),\n             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10]})",
            "text/html": "<style>#sk-container-id-3 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-3 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-3 pre {\n  padding: 0;\n}\n\n#sk-container-id-3 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-3 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-3 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-3 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-3 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-3 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-3 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-3 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-3 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-3 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-3 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-3 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-3 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-3 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n#sk-container-id-3 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-3 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-3 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-3 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-3 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-3 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-3 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-3 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=Ridge(),\n             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=Ridge(),\n             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10]})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: Ridge</label><div class=\"sk-toggleable__content fitted\"><pre>Ridge()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;Ridge<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.Ridge.html\">?<span>Documentation for Ridge</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>Ridge()</pre></div> </div></div></div></div></div></div></div></div></div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 44
    },
    {
      "cell_type": "code",
      "source": "best_model = grid_search.best_estimator_\nbest_model",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 45,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Ridge(alpha=1)",
            "text/html": "<style>#sk-container-id-4 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-4 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-4 pre {\n  padding: 0;\n}\n\n#sk-container-id-4 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-4 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-4 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-4 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-4 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-4 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-4 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-4 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-4 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-4 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-4 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-4 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-4 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-4 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-4 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-4 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n#sk-container-id-4 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-4 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-4 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-4 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-4 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-4 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-4 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-4 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-4 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-4 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Ridge<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.Ridge.html\">?<span>Documentation for Ridge</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Ridge(alpha=1)</pre></div> </div></div></div></div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 45
    },
    {
      "cell_type": "code",
      "source": "y_pred = grid_search.predict(X_pf)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 41
    },
    {
      "cell_type": "code",
      "source": "mse = -cross_val_score(best_model, X_pf, y, \n                       scoring='neg_mean_squared_error', \n                       cv=5)\nr2 = cross_val_score(best_model, X_pf, y, \n                     scoring='r2', \n                     cv=5)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 46
    },
    {
      "cell_type": "code",
      "source": "print(\"Mean Square Error:\", mse.mean())\nprint(\"R2 Score:\", r2.mean())",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Mean Square Error: 172816.64569997336\nR2 Score: 0.2789678362300345\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 48
    },
    {
      "cell_type": "markdown",
      "source": "**Result from ChatGPT**  \n\nHere is a Python code that performs the tasks you specified. It uses polynomial features for some of the attributes in a data frame, performs grid search on a Ridge regression model, includes cross-validation, and evaluates the resulting model's MSE (Mean Squared Error) and R² values.\n\n```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import GridSearchCV, train_test_split, cross_val_predict\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Step 1: Create a sample dataframe or load your dataset\n# Assume `df` is your DataFrame containing the data\n\n# Example: A dataframe with some attributes\ndata = {\n    'CPU_frequency': [2.3, 3.0, 2.8, 2.5, 3.2],\n    'RAM_GB': [8, 16, 8, 32, 16],\n    'Storage_GB_SSD': [256, 512, 128, 1024, 512],\n    'CPU_core': [4, 6, 4, 8, 6],\n    'Price': [1000, 1500, 1100, 1800, 1600]\n}\n\ndf = pd.DataFrame(data)\n\n# Step 2: Define features and target\nX = df[['CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'CPU_core']]  # Features\ny = df['Price']  # Target\n\n# Step 3: Create polynomial features for some attributes\npoly = PolynomialFeatures(degree=2, include_bias=False)\nX_poly = poly.fit_transform(X)\n\n# Step 4: Standardize the data (especially important for Ridge regression)\nscaler = StandardScaler()\nX_poly_scaled = scaler.fit_transform(X_poly)\n\n# Step 5: Define the Ridge regression model\nridge = Ridge()\n\n# Step 6: Perform Grid Search on Ridge regression model\n# Define hyperparameter grid for Ridge model\nh_param_grid = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n\n# Perform Grid Search with Cross-validation (5 folds)\ngrid_search = GridSearchCV(estimator=ridge, param_grid=h_param_grid, cv=5, scoring='neg_mean_squared_error')\ngrid_search.fit(X_poly_scaled, y)\n\n# Step 7: Get the best hyperparameters from the grid search\nprint(\"Best alpha parameter: \", grid_search.best_params_['alpha'])\n\n# Step 8: Evaluate the model with Cross-Validation\n# Perform cross-validated predictions\ny_pred = cross_val_predict(grid_search.best_estimator_, X_poly_scaled, y, cv=5)\n\n# Step 9: Evaluate model performance\nmse = mean_squared_error(y, y_pred)\nr2 = r2_score(y, y_pred)\n\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"R^2 Score: {r2}\")\n```\n##### Explanation:\n1. **Polynomial Features**: The P`olynomialFeatures()` function is used to generate polynomial features for the attributes. In this case, degree 2 features are created.\n2. **Grid Search**: The `GridSearchCV()` is used to search for the best alpha parameter for Ridge regression using cross-validation (5-fold).\n3. **Cross-Validation**: Cross-validation is performed using the `cv=5` argument in the `GridSearchCV()` and also through `cross_val_predict()`.\n4. **Model Evaluation**: The resulting model's performance is evaluated using Mean Squared Error (MSE) and R² score to measure how well the model predicts.  \nLet me know if you want further details or adjustments!",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.model_selection import GridSearchCV, cross_val_predict\n\n# Define features and target\nX = df[['CPU_frequency', 'RAM_GB', \n        'Storage_GB_SSD', 'CPU_core']]\ny = df['Price']\n\n# Create polynomial features for some attributes\npoly = PolynomialFeatures(degree=2, include_bias=False)\nX_poly = poly.fit_transform(X)\ndisplay(X_poly[0])\n\n# Standardize the data (especially important for Ridge regression)\nscaler = StandardScaler()\nX_poly_scaled = scaler.fit_transform(X_poly)\ndisplay(X_poly_scaled[0])\n\n# Define the Ridge regression model\nridge = Ridge()\n\n# Perform Grid Search on Ridge regression model\n# Define hyperparameter grid for Ridge model\nh_param_grid = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n\n# Perform Grid Search with Cross-validation (5 folds)\ngrid_search = GridSearchCV(estimator=ridge, \n                           param_grid=h_param_grid, \n                           cv=5, \n                           scoring='neg_mean_squared_error')\ngrid_search.fit(X_poly_scaled, y)\n\n# Step 7: Get the best hyperparameters from the grid search\nprint(\"Best alpha parameter: \", grid_search.best_params_['alpha'])\n\n# Evaluate the model with Cross-Validation\n# Perform cross-validated predictions\ny_pred = cross_val_predict(grid_search.best_estimator_, \n                           X_poly_scaled, y, \n                           cv=5)\n\n# Step 9: Evaluate model performance\nmse = mean_squared_error(y, y_pred)\nr2 = r2_score(y, y_pred)\n\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"R^2 Score: {r2}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "array([5.51724138e-01, 8.00000000e+00, 2.56000000e+02, 5.00000000e+00,\n       3.04399524e-01, 4.41379310e+00, 1.41241379e+02, 2.75862069e+00,\n       6.40000000e+01, 2.04800000e+03, 4.00000000e+01, 6.55360000e+04,\n       1.28000000e+03, 2.50000000e+01])"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "array([-1.85148175,  0.04748847,  0.29454709, -0.50860609, -1.77049832,\n       -0.77561347, -1.28562575, -1.28153227, -0.08510008,  0.11290304,\n       -0.27942649,  0.29454709, -0.31220354, -0.60776085])"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Best alpha parameter:  1\nMean Squared Error (MSE): 205189.8615745415\nR^2 Score: 0.3759180402499378\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 50
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Authors\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "[Abhishek Gagneja](https://www.linkedin.com/in/abhishek-gagneja-23051987/)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Change Log\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n|-|-|-|-|\n|2023-12-10|0.1|Abhishek Gagneja|Initial Draft created|\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Copyright © 2023 IBM Corporation. All rights reserved.\n",
      "metadata": {}
    }
  ]
}